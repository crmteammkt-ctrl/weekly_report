import os
import sqlite3
import duckdb
import pandas as pd
import numpy as np
import streamlit as st
import gdown

GOOGLE_DRIVE_FILE_ID = "1ETbZl4gU4uqneZ8sJKtXbS80gMgRcuzH"
SQLITE_DB = "thiensondb.db"
DUCKDB_DB = "marketing.duckdb"
TABLE_NAME = "tinhhinhbanhang"


def close_connection():
    # ƒë√≥ng + clear cache_resource ƒë·ªÉ tr√°nh lock file
    try:
        con = get_connection()
        try:
            con.close()
        except Exception:
            pass
    except Exception:
        pass

    try:
        st.cache_resource.clear()
    except Exception:
        pass


def rebuild_duckdb_from_drive():
    close_connection()

    sqlite_tmp = SQLITE_DB + ".tmp"
    if os.path.exists(sqlite_tmp):
        try: os.remove(sqlite_tmp)
        except Exception: pass

    with st.spinner("‚¨áÔ∏è ƒêang t·∫£i DB t·ª´ Google Drive (~500MB)..."):
        url = f"https://drive.google.com/uc?id={GOOGLE_DRIVE_FILE_ID}"
        gdown.download(url, sqlite_tmp, quiet=False)

    if os.path.exists(SQLITE_DB):
        try: os.remove(SQLITE_DB)
        except Exception: pass
    os.replace(sqlite_tmp, SQLITE_DB)

    duck_tmp = DUCKDB_DB + ".tmp"
    if os.path.exists(duck_tmp):
        try: os.remove(duck_tmp)
        except Exception: pass

    with st.spinner("ü¶Ü ƒêang convert SQLite ‚Üí DuckDB..."):
        sqlite_conn = sqlite3.connect(SQLITE_DB)
        df = pd.read_sql(f"SELECT * FROM {TABLE_NAME}", sqlite_conn)
        sqlite_conn.close()

        # clean numeric
        numeric_cols = ["T·ªïng_Gross", "T·ªïng_Net", "CK_%"]
        for col in numeric_cols:
            if col in df.columns:
                s = df[col].astype(str).str.replace("%", "", regex=False).str.replace(",", "", regex=False)
                s = s.replace("", np.nan)
                df[col] = pd.to_numeric(s, errors="coerce")

        duck = duckdb.connect(duck_tmp)
        duck.execute(f"CREATE OR REPLACE TABLE {TABLE_NAME} AS SELECT * FROM df")
        duck.close()

    if os.path.exists(DUCKDB_DB):
        try: os.remove(DUCKDB_DB)
        except Exception: pass
    os.replace(duck_tmp, DUCKDB_DB)

    # clear cache_data ƒë·ªÉ ƒë·ªçc d·ªØ li·ªáu m·ªõi
    try:
        st.cache_data.clear()
    except Exception:
        pass


@st.cache_resource(show_spinner="ü¶Ü Opening DuckDB...")
def get_connection():
    if not os.path.exists(DUCKDB_DB):
        rebuild_duckdb_from_drive()
    return duckdb.connect(DUCKDB_DB, read_only=True)


# ‚úÖ ch·ªâ l·∫•y MIN/MAX ng√†y (nhanh)
@st.cache_data(show_spinner=False)
def get_date_bounds():
    con = get_connection()
    row = con.execute(f'SELECT MIN("Ng√†y") AS min_d, MAX("Ng√†y") AS max_d FROM {TABLE_NAME}').fetchone()
    return pd.to_datetime(row[0], errors="coerce"), pd.to_datetime(row[1], errors="coerce")


# ‚úÖ l·∫•y options filter (nhanh h∆°n load full)
@st.cache_data(show_spinner=False)
def get_filter_options():
    con = get_connection()
    # DISTINCT tr√™n t·ª´ng c·ªôt, tr√°nh k√©o full table
    loai = con.execute(f'SELECT DISTINCT "LoaiCT" FROM {TABLE_NAME} WHERE "LoaiCT" IS NOT NULL').df()["LoaiCT"].tolist()
    brand = con.execute(f'SELECT DISTINCT "Brand" FROM {TABLE_NAME} WHERE "Brand" IS NOT NULL').df()["Brand"].tolist()
    region = con.execute(f'SELECT DISTINCT "Region" FROM {TABLE_NAME} WHERE "Region" IS NOT NULL').df()["Region"].tolist()
    store = con.execute(f'SELECT DISTINCT "ƒêi·ªÉm_mua_h√†ng" FROM {TABLE_NAME} WHERE "ƒêi·ªÉm_mua_h√†ng" IS NOT NULL').df()["ƒêi·ªÉm_mua_h√†ng"].tolist()
    return sorted(loai), sorted(brand), sorted(region), sorted(store)


# ‚úÖ load d·ªØ li·ªáu theo filter (ch·ªâ k√©o ph·∫ßn c·∫ßn)
@st.cache_data(show_spinner="üì¶ Loading filtered data...")
def load_data_filtered(start_date, end_date, loaiCT_list, brand_list, region_list, store_list):
    con = get_connection()

    sql = f"""
        SELECT
            "Ng√†y",
            "LoaiCT",
            "Brand",
            "Region",
            "T·ªânh_TP",
            "ƒêi·ªÉm_mua_h√†ng",
            "Nh√≥m_h√†ng",
            "T√™n_h√†ng",
            "S·ªë_CT",
            "t√™n_KH",
            "Ki·ªÉm_tra_t√™n",
            "S·ªë_ƒëi·ªán_tho·∫°i",
            "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i",
            "T·ªïng_Gross",
            "T·ªïng_Net"
        FROM {TABLE_NAME}
        WHERE "Ng√†y" BETWEEN ? AND ?
          AND ("LoaiCT" IN (SELECT * FROM UNNEST(?)))
          AND ("Brand"  IN (SELECT * FROM UNNEST(?)))
          AND ("Region" IN (SELECT * FROM UNNEST(?)))
          AND ("ƒêi·ªÉm_mua_h√†ng" IN (SELECT * FROM UNNEST(?)))
    """

    df = con.execute(
        sql,
        [pd.to_datetime(start_date), pd.to_datetime(end_date),
         loaiCT_list, brand_list, region_list, store_list]
    ).df()

    df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
    df = df.dropna(subset=["Ng√†y"])

    for c in ["T·ªïng_Gross", "T·ªïng_Net"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    return df


@st.cache_data(show_spinner=False)
def first_purchase():
    con = get_connection()
    df = con.execute(f'''
        SELECT "S·ªë_ƒëi·ªán_tho·∫°i", MIN("Ng√†y") AS First_Date
        FROM {TABLE_NAME}
        GROUP BY "S·ªë_ƒëi·ªán_tho·∫°i"
    ''').df()
    df["First_Date"] = pd.to_datetime(df["First_Date"], errors="coerce")
    return df
