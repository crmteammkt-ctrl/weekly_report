import pandas as pd
import numpy as np
import streamlit as st
from io import BytesIO
from datetime import datetime

from load_data import get_active_data, set_active_data, first_purchase  # d√πng chung parquet

# =====================================================
# Helper: ƒê·ªçc & g·ªôp nhi·ªÅu file parquet upload
# =====================================================
@st.cache_data(show_spinner="üì¶ ƒêang ƒë·ªçc file parquet upload...")
def load_parquet_from_upload(files):
    if not files:
        return pd.DataFrame()

    dfs = []
    for f in files:
        d = pd.read_parquet(f)
        dfs.append(d)

    df = pd.concat(dfs, ignore_index=True)

    # Chu·∫©n ho√° c·ªôt Ng√†y
    if "Ng√†y" in df.columns:
        df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
        df = df.dropna(subset=["Ng√†y"])

    return df


# =====================================================
# Utils
# =====================================================
def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Data")
    return output.getvalue()


def fix_float(df, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
    return df


# =====================================================
# Page config
# =====================================================
st.set_page_config(page_title="Marketing Revenue Dashboard", layout="wide")
st.title("üìä MARKETING REVENUE DASHBOARD ‚Äì T·ªïng quan")

# =====================================================
# CH·ªåN NGU·ªíN D·ªÆ LI·ªÜU CHO TO√ÄN APP
# =====================================================
with st.sidebar:
    st.markdown("### üóÇ Ch·ªçn ngu·ªìn d·ªØ li·ªáu")

    src_choice = st.radio(
        "Ngu·ªìn d·ªØ li·ªáu (√°p d·ª•ng cho t·∫•t c·∫£ trang)",
        [
            "D√πng d·ªØ li·ªáu hi·ªán t·∫°i",
            "Upload file parquet t·ª´ m√°y",
            "Quay l·∫°i d·ªØ li·ªáu m·∫∑c ƒë·ªãnh",
        ],
        index=0,
        key="data_source_main",
    )

    uploaded_files = None
    if src_choice == "Upload file parquet t·ª´ m√°y":
        uploaded_files = st.file_uploader(
            "üìÅ Ch·ªçn 1 ho·∫∑c nhi·ªÅu file .parquet",
            type=["parquet"],
            accept_multiple_files=True,
            key="parquet_uploader_main",
        )

# X·ª≠ l√Ω l·ª±a ch·ªçn ngu·ªìn
if src_choice == "Upload file parquet t·ª´ m√°y" and uploaded_files:
    df_up = load_parquet_from_upload(uploaded_files)
    if df_up.empty:
        st.warning("‚ö† File parquet upload kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá. V·∫´n gi·ªØ d·ªØ li·ªáu c≈©.")
    else:
        set_active_data(df_up, source="upload")
        st.success(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ {len(uploaded_files)} file parquet upload")

elif src_choice == "Quay l·∫°i d·ªØ li·ªáu m·∫∑c ƒë·ªãnh":
    # Xo√° active_df ƒë·ªÉ get_active_data() t·ª± load l·∫°i parquet m·∫∑c ƒë·ªãnh
    if "active_df" in st.session_state:
        del st.session_state["active_df"]
    _ = get_active_data()
    st.success("‚Ü© ƒê√£ quay l·∫°i d√πng d·ªØ li·ªáu m·∫∑c ƒë·ªãnh tr√™n server")

# Sau khi c√≥ th·ªÉ ƒë√£ thay ƒë·ªïi, lu√¥n l·∫•y l·∫°i d·ªØ li·ªáu ƒëang active
df = get_active_data()

# Hi·ªÉn th·ªã ngu·ªìn ƒëang d√πng
st.sidebar.caption(
    "üîé ƒêang d√πng ngu·ªìn: **{}**".format(
        st.session_state.get("active_source", "default")
    )
)

# =====================================================
# SIDEBAR FILTER
# =====================================================
with st.sidebar:
    st.header("üéõÔ∏è B·ªô l·ªçc d·ªØ li·ªáu (T·ªïng quan)")

    time_type = st.selectbox("Ph√¢n t√≠ch theo", ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω", "NƒÉm"])

    start_date = st.date_input("T·ª´ ng√†y", df["Ng√†y"].min())
    end_date   = st.date_input("ƒê·∫øn ng√†y", df["Ng√†y"].max())

    # ----- Brand -----
    brand_options = sorted(df["Brand"].dropna().unique())
    brand_raw = st.multiselect(
        "Brand",
        ["All"] + brand_options,
        default=["All"]
    )

    # danh s√°ch Brand th·ª±c s·ª± ƒë∆∞·ª£c ch·ªçn (ƒë·ªÉ build Region)
    brand_for_region = brand_options if (not brand_raw or "All" in brand_raw) else brand_raw
    df_for_region = df[df["Brand"].isin(brand_for_region)]

    # ----- Region ph·ª• thu·ªôc Brand -----
    region_options = sorted(df_for_region["Region"].dropna().unique())
    region_raw = st.multiselect(
        "Region",
        ["All"] + region_options,
        default=["All"]
    )

    # danh s√°ch Region th·ª±c s·ª± ƒë∆∞·ª£c ch·ªçn (ƒë·ªÉ build Store)
    region_for_store = region_options if (not region_raw or "All" in region_raw) else region_raw
    df_for_store = df_for_region[df_for_region["Region"].isin(region_for_store)]

    # ----- C·ª≠a h√†ng ph·ª• thu·ªôc Brand + Region -----
    store_options = sorted(df_for_store["ƒêi·ªÉm_mua_h√†ng"].dropna().unique())
    store_raw = st.multiselect(
        "C·ª≠a h√†ng",
        ["All"] + store_options,
        default=["All"]
    )

    # Lo·∫°i CT (kh√¥ng ph·ª• thu·ªôc)
    loaiCT_options = sorted(df["LoaiCT"].dropna().unique())
    loaiCT_raw = st.multiselect(
        "Lo·∫°i CT",
        ["All"] + loaiCT_options
    )

# =====================================================
# CLEAN FILTER
# =====================================================
def clean_filter(values, all_values):
    if (not values) or ("All" in values):
        return all_values
    return values

loaiCT_filter = clean_filter(loaiCT_raw, loaiCT_options)
brand_filter  = clean_filter(brand_raw,  brand_options)
region_filter = clean_filter(region_raw, region_options)
store_filter  = clean_filter(store_raw,  store_options)

# =====================================================
# APPLY FILTER
# =====================================================
@st.cache_data(show_spinner=False)
def apply_filters(df, start_date, end_date, loaiCT, brand, region, store):
    return df[
        (df["Ng√†y"] >= start_date) &
        (df["Ng√†y"] <= end_date) &
        (df["LoaiCT"].isin(loaiCT)) &
        (df["Brand"].isin(brand)) &
        (df["Region"].isin(region)) &
        (df["ƒêi·ªÉm_mua_h√†ng"].isin(store))
    ]

df_f = apply_filters(
    df,
    pd.to_datetime(start_date),
    pd.to_datetime(end_date),
    loaiCT_filter,
    brand_filter,
    region_filter,
    store_filter,
)


# =====================================================
# TIME COLUMN
# =====================================================
df_f_time = df_f.copy()
if time_type == "Ng√†y":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.date
elif time_type == "Tu·∫ßn":
    iso = df_f_time["Ng√†y"].dt.isocalendar()  # year, week, day
    df_f_time["Time"] = (
        "Tu·∫ßn " + iso["week"].astype(str).str.zfill(2) + "/" + iso["year"].astype(str)
    )
elif time_type == "Th√°ng":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("M").astype(str)
elif time_type == "Qu√Ω":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("Q").astype(str)
elif time_type == "NƒÉm":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.year

# =====================================================
# KPI
# =====================================================
gross = df_f["T·ªïng_Gross"].sum()
net = df_f["T·ªïng_Net"].sum()
orders = df_f["S·ªë_CT"].nunique()
customers = df_f["S·ªë_ƒëi·ªán_tho·∫°i"].nunique()
ck_rate = (1 - net / gross) * 100 if gross > 0 else 0

c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Gross", f"{gross:,.0f}")
c2.metric("Net", f"{net:,.0f}")
c3.metric("CK %", f"{ck_rate:.2f}%")
c4.metric("ƒê∆°n h√†ng", orders)
c5.metric("Kh√°ch h√†ng", customers)

# =====================================================
# TIME GROUP
# =====================================================
@st.cache_data(show_spinner=False)
def group_time(df_f, time_type):
    freq_map = {"Ng√†y": "D", "Tu·∫ßn": "W", "Th√°ng": "ME", "Qu√Ω": "Q", "NƒÉm": "Y"}
    d = (
        df_f.set_index("Ng√†y")
        .resample(freq_map[time_type])
        .agg(
            Gross=("T·ªïng_Gross", "sum"),
            Net=("T·ªïng_Net", "sum"),
            Orders=("S·ªë_CT", "nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        )
        .reset_index()
    )
    d["CK_%"] = np.where(d["Gross"] > 0, (1 - d["Net"] / d["Gross"]) * 100, 0)
    d["Net_prev"] = d["Net"].shift(1)
    d["Growth_%"] = np.where(
        d["Net_prev"] > 0, (d["Net"] - d["Net_prev"]) / d["Net_prev"] * 100, 0
    )
    return d


df_time = fix_float(df_f, ["T·ªïng_Gross", "T·ªïng_Net"])
df_time = group_time(df_f, time_type)
df_time = fix_float(df_time, ["CK_%", "Growth_%"])

st.subheader(f"‚è± Theo th·ªùi gian ({time_type})")
st.dataframe(df_time, width="stretch")

# =====================================================
# REGION + TIME
# =====================================================
@st.cache_data(show_spinner=False)
def group_region_time(df):
    d = (
        df.groupby(["Time", "Region"])
        .agg(
            Gross=("T·ªïng_Gross", "sum"),
            Net=("T·ªïng_Net", "sum"),
            Orders=("S·ªë_CT", "nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        )
        .reset_index()
    )
    d["CK_%"] = np.where(d["Gross"] > 0, (d["Gross"] - d["Net"]) / d["Gross"] * 100, 0)
    return d.sort_values(["Time", "Net"], ascending=[True, False])


df_region_time = fix_float(group_region_time(df_f_time), ["CK_%"])
st.subheader(f"üåç Theo Region + {time_type}")
st.dataframe(df_region_time, width="stretch")

# -------------------------
# B√°o c√°o c·ª≠a h√†ng
# -------------------------
st.subheader("üè™ T·ªïng quan theo C·ª≠a h√†ng")

df_store = (
    df_f.groupby("ƒêi·ªÉm_mua_h√†ng")
    .agg(
        Gross=("T·ªïng_Gross", "sum"),
        Net=("T·ªïng_Net", "sum"),
        Orders=("S·ªë_CT", "nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
    )
    .reset_index()
)
df_store["CK_%"] = np.where(
    df_store["Gross"] > 0,
    (df_store["Gross"] - df_store["Net"]) / df_store["Gross"] * 100,
    0,
).round(2)

st.dataframe(df_store.sort_values("Net", ascending=False), width="stretch")

# -------------------------
# B√°o c√°o nh√≥m s·∫£n ph·∫©m
# -------------------------
df_product = df_f.copy()
st.subheader("üì¶ Theo Nh√≥m SP / M√£ NB")

col1, col2 = st.columns(2)
with col1:
    nhom_sp_selected = st.multiselect(
        "üì¶ Ch·ªçn Nh√≥m SP", sorted(df_product["Nh√≥m_h√†ng"].dropna().unique())
    )
with col2:
    ten_sp_selected = st.multiselect(
        "üè∑Ô∏è Ch·ªçn M√£ NB", sorted(df_product["M√£_NB"].dropna().unique())
    )

if nhom_sp_selected:
    df_product = df_product[df_product["Nh√≥m_h√†ng"].isin(nhom_sp_selected)]
if ten_sp_selected:
    df_product = df_product[df_product["M√£_NB"].isin(ten_sp_selected)]

df_product_group = (
    df_product.groupby("M√£_NB")
    .agg(
        Gross=("T·ªïng_Gross", "sum"),
        Net=("T·ªïng_Net", "sum"),
        Orders=("S·ªë_CT", "nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
    )
    .reset_index()
    .sort_values("Net", ascending=False)
)

st.dataframe(df_product_group, width="stretch")
