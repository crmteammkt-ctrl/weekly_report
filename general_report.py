# pages/00_general_report.py

import pandas as pd
import numpy as np
import streamlit as st
from io import BytesIO
from datetime import datetime

from load_data import get_active_data, set_active_data, first_purchase

# =====================================================
# Utils
# =====================================================
def to_excel(df: pd.DataFrame) -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Data")
    return output.getvalue()


def fix_float(df: pd.DataFrame, cols) -> pd.DataFrame:
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
    return df


# =====================================================
# Page config
# =====================================================
st.set_page_config(page_title="Marketing Revenue Dashboard", layout="wide")
st.title("üìä MARKETING REVENUE DASHBOARD ‚Äì T·ªïng quan")

# =====================================================
# CH·ªåN NGU·ªíN D·ªÆ LI·ªÜU CHO TO√ÄN APP
# =====================================================
with st.sidebar:
    st.markdown("### üóÇ Ch·ªçn ngu·ªìn d·ªØ li·ªáu")

    src_choice = st.radio(
        "Ngu·ªìn d·ªØ li·ªáu (√°p d·ª•ng cho t·∫•t c·∫£ trang)",
        [
            "D√πng d·ªØ li·ªáu hi·ªán t·∫°i",
            "Upload file parquet t·ª´ m√°y",
            "Quay l·∫°i d·ªØ li·ªáu m·∫∑c ƒë·ªãnh",
        ],
        index=0,
        key="data_source_main",
    )

    uploaded_files = None
    if src_choice == "Upload file parquet t·ª´ m√°y":
        uploaded_files = st.file_uploader(
            "üìÅ Ch·ªçn 1 ho·∫∑c nhi·ªÅu file .parquet",
            type=["parquet"],
            accept_multiple_files=True,
            key="parquet_uploader_main",
        )

# X·ª≠ l√Ω l·ª±a ch·ªçn ngu·ªìn
if src_choice == "Upload file parquet t·ª´ m√°y" and uploaded_files:
    # KH√îNG cache ƒë·ªÉ tr√°nh gi·ªØ nhi·ªÅu b·∫£n copy
    dfs = [pd.read_parquet(f) for f in uploaded_files]
    df_up = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    if df_up.empty:
        st.warning("‚ö† File parquet upload kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá. V·∫´n gi·ªØ d·ªØ li·ªáu c≈©.")
    else:
        set_active_data(df_up, source="upload")
        st.success(
            f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ {len(uploaded_files)} file parquet upload"
        )

elif src_choice == "Quay l·∫°i d·ªØ li·ªáu m·∫∑c ƒë·ªãnh":
    if "active_df" in st.session_state:
        del st.session_state["active_df"]
    _ = get_active_data()
    st.success("‚Ü© ƒê√£ quay l·∫°i d√πng d·ªØ li·ªáu m·∫∑c ƒë·ªãnh tr√™n server")

# Lu√¥n l·∫•y l·∫°i d·ªØ li·ªáu ƒëang active
df = get_active_data()
st.sidebar.caption(
    "üîé ƒêang d√πng ngu·ªìn: **{}**".format(
        st.session_state.get("active_source", "default")
    )
)

# B·∫£o ƒë·∫£m c·ªôt Ng√†y chu·∫©n
if "Ng√†y" in df.columns:
    df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
    df = df.dropna(subset=["Ng√†y"])

if df.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch. Ki·ªÉm tra l·∫°i ngu·ªìn d·ªØ li·ªáu.")
    st.stop()

# =====================================================
# SIDEBAR FILTER (c√≥ li√™n k·∫øt Brand ‚Üí Region ‚Üí C·ª≠a h√†ng)
# =====================================================
with st.sidebar:
    st.header("üéõÔ∏è B·ªô l·ªçc d·ªØ li·ªáu (T·ªïng quan)")

    time_type = st.selectbox(
        "Ph√¢n t√≠ch theo", ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω", "NƒÉm"]
    )

    start_date = st.date_input("T·ª´ ng√†y", df["Ng√†y"].min().date())
    end_date = st.date_input("ƒê·∫øn ng√†y", df["Ng√†y"].max().date())

    # Lo·∫°i CT ƒë·ªôc l·∫≠p
    all_loaiCT = sorted(df["LoaiCT"].dropna().unique())
    loaiCT_filter = st.multiselect(
        "Lo·∫°i CT", all_loaiCT, default=all_loaiCT
    )

    # Cascading Brand -> Region -> C·ª≠a h√†ng
    all_brand = sorted(df["Brand"].dropna().unique())
    brand_filter = st.multiselect(
        "Brand", all_brand, default=all_brand
    )

    df_brand = df[df["Brand"].isin(brand_filter)]

    all_region = sorted(df_brand["Region"].dropna().unique())
    region_filter = st.multiselect(
        "Region", all_region, default=all_region
    )

    df_brand_region = df_brand[df_brand["Region"].isin(region_filter)]

    all_store = sorted(df_brand_region["ƒêi·ªÉm_mua_h√†ng"].dropna().unique())
    store_filter = st.multiselect(
        "C·ª≠a h√†ng", all_store, default=all_store
    )

# =====================================================
# APPLY FILTER
# =====================================================
def apply_filters(
    df: pd.DataFrame,
    start_date,
    end_date,
    loaiCT,
    brand,
    region,
    store,
) -> pd.DataFrame:
    mask = (
        (df["Ng√†y"] >= pd.to_datetime(start_date))
        & (df["Ng√†y"] <= pd.to_datetime(end_date))
        & (df["LoaiCT"].isin(loaiCT))
        & (df["Brand"].isin(brand))
        & (df["Region"].isin(region))
        & (df["ƒêi·ªÉm_mua_h√†ng"].isin(store))
    )
    return df.loc[mask]


df_f = apply_filters(
    df,
    start_date,
    end_date,
    loaiCT_filter,
    brand_filter,
    region_filter,
    store_filter,
)

if df_f.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu sau khi √°p b·ªô l·ªçc.")
    st.stop()

# =====================================================
# TIME COLUMN
# =====================================================
df_f_time = df_f.copy()
if time_type == "Ng√†y":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.date
elif time_type == "Tu·∫ßn":
    iso = df_f_time["Ng√†y"].dt.isocalendar()
    df_f_time["Time"] = (
        "Tu·∫ßn " + iso["week"].astype(str).str.zfill(2) + "/" + iso["year"].astype(str)
    )
elif time_type == "Th√°ng":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("M").astype(str)
elif time_type == "Qu√Ω":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("Q").astype(str)
elif time_type == "NƒÉm":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.year

# =====================================================
# KPI
# =====================================================
gross = df_f["T·ªïng_Gross"].sum()
net = df_f["T·ªïng_Net"].sum()
orders = df_f["S·ªë_CT"].nunique()
customers = df_f["S·ªë_ƒëi·ªán_tho·∫°i"].nunique()
ck_rate = (1 - net / gross) * 100 if gross > 0 else 0

c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Gross", value=f"{gross:,.0f}")
c2.metric("Net", value=f"{net:,.0f}")
c3.metric("CK %", value=f"{ck_rate:.2f}%")
c4.metric("ƒê∆°n h√†ng", orders)
c5.metric("Kh√°ch h√†ng", customers)

# =====================================================
# TIME GROUP
# =====================================================
def group_time(df_f: pd.DataFrame, time_type: str) -> pd.DataFrame:
    freq_map = {"Ng√†y": "D", "Tu·∫ßn": "W", "Th√°ng": "ME", "Qu√Ω": "Q", "NƒÉm": "Y"}
    d = (
        df_f.set_index("Ng√†y")
        .resample(freq_map[time_type])
        .agg(
            Gross=("T·ªïng_Gross", "sum"),
            Net=("T·ªïng_Net", "sum"),
            Orders=("S·ªë_CT", "nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        )
        .reset_index()
    )
    d["CK_%"] = np.where(d["Gross"] > 0, (1 - d["Net"] / d["Gross"]) * 100, 0)
    d["Net_prev"] = d["Net"].shift(1)
    d["Growth_%"] = np.where(
        d["Net_prev"] > 0, (d["Net"] - d["Net_prev"]) / d["Net_prev"] * 100, 0
    )
    return d


df_time = group_time(df_f, time_type)
df_time = fix_float(df_time, ["CK_%", "Growth_%"])

st.subheader(f"‚è± Theo th·ªùi gian ({time_type})")
st.dataframe(df_time, width="stretch")

# =====================================================
# REGION + TIME
# =====================================================
def group_region_time(df: pd.DataFrame) -> pd.DataFrame:
    d = (
        df.groupby(["Time", "Region"])
        .agg(
            Gross=("T·ªïng_Gross", "sum"),
            Net=("T·ªïng_Net", "sum"),
            Orders=("S·ªë_CT", "nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        )
        .reset_index()
    )
    d["CK_%"] = np.where(
        d["Gross"] > 0, (d["Gross"] - d["Net"]) / d["Gross"] * 100, 0
    )
    return d.sort_values(["Time", "Net"], ascending=[True, False])


df_region_time = fix_float(group_region_time(df_f_time), ["CK_%"])
st.subheader(f"üåç Theo Region + {time_type}")
st.dataframe(df_region_time, width="stretch")

# -------------------------
# B√°o c√°o c·ª≠a h√†ng
# -------------------------
st.subheader("üè™ T·ªïng quan theo C·ª≠a h√†ng")

df_store = (
    df_f.groupby("ƒêi·ªÉm_mua_h√†ng")
    .agg(
        Gross=("T·ªïng_Gross", "sum"),
        Net=("T·ªïng_Net", "sum"),
        Orders=("S·ªë_CT", "nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
    )
    .reset_index()
)
df_store["CK_%"] = np.where(
    df_store["Gross"] > 0,
    (df_store["Gross"] - df_store["Net"]) / df_store["Gross"] * 100,
    0,
).round(2)

st.dataframe(df_store.sort_values("Net", ascending=False), width="stretch")

# -------------------------
# B√°o c√°o nh√≥m s·∫£n ph·∫©m
# -------------------------
df_product = df_f.copy()
st.subheader("üì¶ Theo Nh√≥m SP / M√£ NB")

col1, col2 = st.columns(2)
with col1:
    nhom_sp_selected = st.multiselect(
        "üì¶ Ch·ªçn Nh√≥m SP", sorted(df_product["Nh√≥m_h√†ng"].dropna().unique())
    )
with col2:
    ten_sp_selected = st.multiselect(
        "üè∑Ô∏è Ch·ªçn M√£ NB", sorted(df_product["M√£_NB"].dropna().unique())
    )

if nhom_sp_selected:
    df_product = df_product[df_product["Nh√≥m_h√†ng"].isin(nhom_sp_selected)]
if ten_sp_selected:
    df_product = df_product[df_product["M√£_NB"].isin(ten_sp_selected)]

df_product_group = (
    df_product.groupby("M√£_NB")
    .agg(
        Gross=("T·ªïng_Gross", "sum"),
        Net=("T·ªïng_Net", "sum"),
        Orders=("S·ªë_CT", "nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
    )
    .reset_index()
    .sort_values("Net", ascending=False)
)

st.dataframe(df_product_group, width="stretch")
