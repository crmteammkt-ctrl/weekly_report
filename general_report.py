import pandas as pd
import numpy as np
import streamlit as st
from io import BytesIO
from datetime import datetime

from load_data import load_data  # d√πng chung parquet
# =====================================================
# Helper: ƒê·ªçc & g·ªôp nhi·ªÅu file parquet upload
# =====================================================
@st.cache_data(show_spinner="üì¶ ƒêang ƒë·ªçc file parquet upload...")
def load_parquet_from_upload(files):
    if not files:
        return pd.DataFrame()

    dfs = []
    for f in files:
        d = pd.read_parquet(f)
        dfs.append(d)

    df = pd.concat(dfs, ignore_index=True)

    # Chu·∫©n ho√° c·ªôt Ng√†y
    if "Ng√†y" in df.columns:
        df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
        df = df.dropna(subset=["Ng√†y"])

    return df
# =====================================================
# Utils
# =====================================================
def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Data")
    return output.getvalue()

def fix_float(df, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
    return df

# =====================================================
# Page config
# =====================================================
st.set_page_config(page_title="Marketing Revenue Dashboard", layout="wide")
st.title("üìä MARKETING REVENUE DASHBOARD ‚Äì T·ªïng quan")

# =====================================================
# LOAD DATA (c√≥ cache ·ªü load_data.py)
# =====================================================
# =====================================================
# LOAD DATA (m·∫∑c ƒë·ªãnh + upload linh ho·∫°t)
# =====================================================
with st.sidebar:
    st.markdown("### üóÇ Ch·ªçn ngu·ªìn d·ªØ li·ªáu")

    data_source = st.radio(
        "Ngu·ªìn d·ªØ li·ªáu",
        ["D√πng d·ªØ li·ªáu m·∫∑c ƒë·ªãnh tr√™n server", "Upload file parquet t·ª´ m√°y"],
        index=0,
        key="data_source_main"
    )

    uploaded_files = None
    if data_source == "Upload file parquet t·ª´ m√°y":
        uploaded_files = st.file_uploader(
            "üìÅ Ch·ªçn 1 ho·∫∑c nhi·ªÅu file .parquet",
            type=["parquet"],
            accept_multiple_files=True,
            key="parquet_uploader_main"
        )

# Quy·∫øt ƒë·ªãnh d√πng d·ªØ li·ªáu n√†o
if data_source == "Upload file parquet t·ª´ m√°y" and uploaded_files:
    df = load_parquet_from_upload(uploaded_files)
    if df.empty:
        st.warning("‚ö† File parquet upload kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá. ƒêang d√πng DataFrame r·ªóng.")
    else:
        st.success(f"‚úÖ ƒêang d√πng d·ªØ li·ªáu t·ª´ {len(uploaded_files)} file parquet upload")
else:
    df = load_data()
    st.sidebar.info("üì¶ ƒêang d√πng d·ªØ li·ªáu parquet m·∫∑c ƒë·ªãnh tr√™n server (load_data).")

df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
df = df.dropna(subset=["Ng√†y"])

# =====================================================
# SIDEBAR
# =====================================================
with st.sidebar:
    st.header("üéõÔ∏è B·ªô l·ªçc d·ªØ li·ªáu (T·ªïng quan)")

    time_type = st.selectbox("Ph√¢n t√≠ch theo", ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω", "NƒÉm"])

    start_date = st.date_input("T·ª´ ng√†y", df["Ng√†y"].min())
    end_date   = st.date_input("ƒê·∫øn ng√†y", df["Ng√†y"].max())

    loaiCT_filter = st.multiselect("Lo·∫°i CT", ["All"] + sorted(df["LoaiCT"].dropna().unique()))
    brand_filter  = st.multiselect("Brand", ["All"] + sorted(df["Brand"].dropna().unique()))
    region_filter = st.multiselect("Region", ["All"] + sorted(df["Region"].dropna().unique()))
    store_filter  = st.multiselect("C·ª≠a h√†ng", ["All"] + sorted(df["ƒêi·ªÉm_mua_h√†ng"].dropna().unique()))

# =====================================================
# CLEAN FILTER
# =====================================================
def clean_filter(values, all_values):
    if not values or "All" in values:
        return all_values
    return values

loaiCT_filter = clean_filter(loaiCT_filter, df["LoaiCT"].unique())
brand_filter  = clean_filter(brand_filter,  df["Brand"].unique())
region_filter = clean_filter(region_filter, df["Region"].unique())
store_filter  = clean_filter(store_filter,  df["ƒêi·ªÉm_mua_h√†ng"].unique())

# =====================================================
# APPLY FILTER
# =====================================================
@st.cache_data(show_spinner=False)
def apply_filters(df, start_date, end_date, loaiCT, brand, region, store):
    return df[
        (df["Ng√†y"] >= start_date) &
        (df["Ng√†y"] <= end_date) &
        (df["LoaiCT"].isin(loaiCT)) &
        (df["Brand"].isin(brand)) &
        (df["Region"].isin(region)) &
        (df["ƒêi·ªÉm_mua_h√†ng"].isin(store))
    ]

df_f = apply_filters(
    df,
    pd.to_datetime(start_date),
    pd.to_datetime(end_date),
    loaiCT_filter,
    brand_filter,
    region_filter,
    store_filter
)

# =====================================================
# TIME COLUMN
# =====================================================
df_f_time = df_f.copy()
if time_type == "Ng√†y":   df_f_time["Time"] = df_f_time["Ng√†y"].dt.date
elif time_type == "Tu·∫ßn": df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("W").astype(str)
elif time_type == "Th√°ng": df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("M").astype(str)
elif time_type == "Qu√Ω":  df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("Q").astype(str)
elif time_type == "NƒÉm":  df_f_time["Time"] = df_f_time["Ng√†y"].dt.year

# =====================================================
# KPI
# =====================================================
gross = df_f["T·ªïng_Gross"].sum()
net   = df_f["T·ªïng_Net"].sum()
orders = df_f["S·ªë_CT"].nunique()
customers = df_f["S·ªë_ƒëi·ªán_tho·∫°i"].nunique()
ck_rate = (1 - net / gross) * 100 if gross > 0 else 0

c1,c2,c3,c4,c5 = st.columns(5)
c1.metric("Gross", f"{gross:,.0f}")
c2.metric("Net", f"{net:,.0f}")
c3.metric("CK %", f"{ck_rate:.2f}%")
c4.metric("ƒê∆°n h√†ng", orders)
c5.metric("Kh√°ch h√†ng", customers)

# =====================================================
# TIME GROUP
# =====================================================
@st.cache_data(show_spinner=False)
def group_time(df_f, time_type):
    freq_map = {"Ng√†y":"D","Tu·∫ßn":"W","Th√°ng":"ME","Qu√Ω":"Q","NƒÉm":"Y"}
    d = (
        df_f.set_index("Ng√†y")
        .resample(freq_map[time_type])
        .agg(
            Gross=("T·ªïng_Gross","sum"),
            Net=("T·ªïng_Net","sum"),
            Orders=("S·ªë_CT","nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i","nunique")
        )
        .reset_index()
    )
    d["CK_%"] = np.where(d["Gross"]>0, (1-d["Net"]/d["Gross"])*100, 0)
    d["Net_prev"] = d["Net"].shift(1)
    d["Growth_%"] = np.where(d["Net_prev"]>0, (d["Net"]-d["Net_prev"])/d["Net_prev"]*100, 0)
    return d

df_time = fix_float(group_time(df_f, time_type), ["CK_%", "Growth_%"])

st.subheader(f"‚è± Theo th·ªùi gian ({time_type})")
st.dataframe(df_time, width="stretch")

# =====================================================
# REGION + TIME
# =====================================================
@st.cache_data(show_spinner=False)
def group_region_time(df):
    d = (
        df.groupby(["Time","Region"])
        .agg(
            Gross=("T·ªïng_Gross","sum"),
            Net=("T·ªïng_Net","sum"),
            Orders=("S·ªë_CT","nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i","nunique")
        )
        .reset_index()
    )
    d["CK_%"] = np.where(d["Gross"]>0, (d["Gross"]-d["Net"])/d["Gross"]*100, 0)
    return d.sort_values(["Time","Net"], ascending=[True, False])

df_region_time = fix_float(group_region_time(df_f_time), ["CK_%"])
st.subheader(f"üåç Theo Region + {time_type}")
st.dataframe(df_region_time, width="stretch")

# -------------------------
# B√°o c√°o c·ª≠a h√†ng
# -------------------------
st.subheader("üè™ T·ªïng quan theo C·ª≠a h√†ng")

df_store = (
    df_f.groupby("ƒêi·ªÉm_mua_h√†ng")
    .agg(
        Gross=("T·ªïng_Gross","sum"),
        Net=("T·ªïng_Net","sum"),
        Orders=("S·ªë_CT","nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i","nunique")
    )
    .reset_index()
)
df_store["CK_%"] = np.where(
    df_store["Gross"]>0,
    (df_store["Gross"] - df_store["Net"]) / df_store["Gross"] * 100,
    0
).round(2)

st.dataframe(df_store.sort_values("Net", ascending=False), width="stretch")

# -------------------------
# B√°o c√°o nh√≥m s·∫£n ph·∫©m
# -------------------------
df_product = df_f.copy()
st.subheader("üì¶ Theo Nh√≥m SP / T√™n h√†ng")

col1,col2 = st.columns(2)
with col1:
    nhom_sp_selected = st.multiselect("üì¶ Ch·ªçn Nh√≥m SP", sorted(df_product["Nh√≥m_h√†ng"].dropna().unique()))
with col2:
    ten_sp_selected = st.multiselect("üè∑Ô∏è Ch·ªçn T√™n h√†ng", sorted(df_product["M√£_NB"].dropna().unique()))

if nhom_sp_selected:
    df_product = df_product[df_product["Nh√≥m_h√†ng"].isin(nhom_sp_selected)]
if ten_sp_selected:
    df_product = df_product[df_product["M√£_NB"].isin(ten_sp_selected)]

df_product_group = (
    df_product.groupby("M√£_NB")
    .agg(
        Gross=("T·ªïng_Gross","sum"),
        Net=("T·ªïng_Net","sum"),
        Orders=("S·ªë_CT","nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i","nunique")
    )
    .reset_index()
    .sort_values("Net", ascending=False)
)

st.dataframe(df_product_group, width="stretch")
