# pages/00_general_report.py
import pandas as pd
import numpy as np
import streamlit as st
from io import BytesIO

from load_data import get_active_data, set_active_data

# =====================================================
# FORMAT HELPERS (an to√†n - kh√¥ng ph·ª• thu·ªôc Streamlit version)
# =====================================================
def fmt_int(x):
    if pd.isna(x):
        return ""
    try:
        return f"{float(x):,.0f}"
    except Exception:
        return ""

def fmt_pct(x, decimals=2, with_sign=False):
    # x ƒëang l√† 20.8 nghƒ©a l√† 20.8%
    if pd.isna(x):
        return ""
    try:
        v = float(x)
        s = f"{v:,.{decimals}f}%"
        if with_sign and v > 0:
            s = "+" + s
        return s
    except Exception:
        return ""

def ensure_datetime(df: pd.DataFrame) -> pd.DataFrame:
    if "Ng√†y" in df.columns:
        df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
        df = df.dropna(subset=["Ng√†y"])
    return df

def fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for c in ["T·ªïng_Gross", "T·ªïng_Net"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# =====================================================
# WEEK HELPERS (TU·∫¶N B·∫ÆT ƒê·∫¶U THEO TH·ª® TU·ª≤ CH·ªåN)
# =====================================================
def week_anchor(dt: pd.Series, week_start: int) -> pd.Series:
    """
    Tr·∫£ v·ªÅ ng√†y "neo" c·ªßa tu·∫ßn theo week_start (0=Mon ... 6=Sun), normalize v·ªÅ 00:00:00
    """
    d = pd.to_datetime(dt)
    return (d - pd.to_timedelta((d.dt.weekday - week_start) % 7, unit="D")).dt.normalize()

def week_label_from_anchor(anchor: pd.Series) -> pd.Series:
    """
    T·∫°o label d·∫°ng 'Tu·∫ßn WW/YYYY' d·ª±a tr√™n anchor.
    D√πng ISO week-year c·ªßa ch√≠nh anchor ƒë·ªÉ ·ªïn ƒë·ªãnh.
    """
    iso = pd.to_datetime(anchor).dt.isocalendar()
    return "Tu·∫ßn " + iso["week"].astype(str).str.zfill(2) + "/" + iso["year"].astype(str)

# =====================================================
# FILTER HELPERS (G·ªåN + LINH HO·∫†T + ALL + RESET)
# =====================================================
GEN_PREFIX = "gen_"

def reset_by_prefix(prefix: str):
    """
    Reset c√°c filter c·ªßa trang theo prefix,
    nh∆∞ng KH√îNG xo√° key d√πng chung to√†n app (vd: app_week_start).
    """
    for k in list(st.session_state.keys()):
        if k == "app_week_start":
            continue
        if k.startswith(prefix):
            st.session_state.pop(k, None)
    st.rerun()


def ms_all(key: str, label: str, options, all_label="All", default_all=True):
    """
    Multiselect c√≥ All:
    - options ƒë·ªïi kh√¥ng crash
    - selection c≈© ƒë∆∞·ª£c gi·ªØ n·∫øu c√≤n h·ª£p l·ªá
    - tr·∫£ v·ªÅ list gi√° tr·ªã th·∫≠t ƒë·ªÉ filter (kh√¥ng g·ªìm All)
    """
    opts = pd.Series(list(options)).dropna().astype(str).str.strip()
    opts = sorted(opts.unique().tolist())
    ui_opts = [all_label] + opts

    if key not in st.session_state:
        st.session_state[key] = [all_label] if default_all else (opts[:1] if opts else [all_label])

    cur = [str(x).strip() for x in st.session_state.get(key, []) if str(x).strip() in ui_opts]
    if not cur:
        cur = [all_label] if default_all else (opts[:1] if opts else [all_label])
        st.session_state[key] = cur

    selected = st.multiselect(label, options=ui_opts, key=key)

    if (not selected) or (all_label in selected):
        return opts
    return [x for x in selected if x in opts]

# =====================================================
# Page config
# =====================================================
st.set_page_config(page_title="Marketing Revenue Dashboard", layout="wide")
st.title("üìä MARKETING REVENUE DASHBOARD ‚Äì T·ªïng quan")

# =====================================================
# CH·ªåN NGU·ªíN D·ªÆ LI·ªÜU CHO TO√ÄN APP
# =====================================================
with st.sidebar:
    st.markdown("### üóÇ Ch·ªçn ngu·ªìn d·ªØ li·ªáu")

    src_choice = st.radio(
        "Ngu·ªìn d·ªØ li·ªáu (√°p d·ª•ng cho t·∫•t c·∫£ trang)",
        ["D√πng d·ªØ li·ªáu hi·ªán t·∫°i", "Upload file parquet t·ª´ m√°y", "Quay l·∫°i d·ªØ li·ªáu m·∫∑c ƒë·ªãnh"],
        index=0,
        key="data_source_main",
    )

    uploaded_files = None
    if src_choice == "Upload file parquet t·ª´ m√°y":
        uploaded_files = st.file_uploader(
            "üìÅ Ch·ªçn 1 ho·∫∑c nhi·ªÅu file .parquet",
            type=["parquet"],
            accept_multiple_files=True,
            key="parquet_uploader_main",
        )

# X·ª≠ l√Ω upload / reset
if src_choice == "Upload file parquet t·ª´ m√°y" and uploaded_files:
    dfs = []
    for f in uploaded_files:
        try:
            dfs.append(pd.read_parquet(f))
        except Exception as e:
            st.warning(f"‚ö† Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {getattr(f, 'name', 'unknown')} ({e})")

    df_up = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()
    df_up = ensure_datetime(df_up)
    df_up = fix_numeric(df_up)

    if df_up.empty:
        st.warning("‚ö† File parquet upload kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá. V·∫´n gi·ªØ d·ªØ li·ªáu c≈©.")
    else:
        set_active_data(df_up, source="upload")
        st.success(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ {len(uploaded_files)} file parquet upload")

    del dfs, df_up

elif src_choice == "Quay l·∫°i d·ªØ li·ªáu m·∫∑c ƒë·ªãnh":
    if "active_df" in st.session_state:
        del st.session_state["active_df"]
    _ = get_active_data()
    st.success("‚Ü© ƒê√£ quay l·∫°i d√πng d·ªØ li·ªáu m·∫∑c ƒë·ªãnh tr√™n server")

# Lu√¥n l·∫•y l·∫°i d·ªØ li·ªáu ƒëang active
df = get_active_data()
st.sidebar.caption("üîé ƒêang d√πng ngu·ªìn: **{}**".format(st.session_state.get("active_source", "default")))

df = ensure_datetime(df)
df = fix_numeric(df)

if df.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch. Ki·ªÉm tra l·∫°i ngu·ªìn d·ªØ li·ªáu.")
    st.stop()

# =====================================================
# SIDEBAR FILTER (G·ªåN + ALL + CASCADE + RESET)
# =====================================================
with st.sidebar:
    st.header("üéõÔ∏è B·ªô l·ªçc d·ªØ li·ªáu (T·ªïng quan)")

    if st.button("üîÑ Reset b·ªô l·ªçc (General)", use_container_width=True):
        reset_by_prefix(GEN_PREFIX)

    time_type = st.selectbox(
        "Ph√¢n t√≠ch theo",
        ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω", "NƒÉm"],
        key=GEN_PREFIX + "time_type",
    )

    # ‚úÖ TU·∫¶N B·∫ÆT ƒê·∫¶U THEO TH·ª® (CH·ªà D√ôNG KHI time_type == 'Tu·∫ßn')
    week_start_label = st.selectbox(
    "Tu·∫ßn b·∫Øt ƒë·∫ßu t·ª´ th·ª©",
    ["Th·ª© 2", "Th·ª© 3", "Th·ª© 4", "Th·ª© 5", "Th·ª© 6", "Th·ª© 7", "Ch·ªß nh·∫≠t"],
    index=0,
    key="app_week_start",  # ‚úÖ KEY CHUNG TO√ÄN APP
)

WEEKDAY_MAP = {
    "Th·ª© 2": 0, "Th·ª© 3": 1, "Th·ª© 4": 2, "Th·ª© 5": 3,
    "Th·ª© 6": 4, "Th·ª© 7": 5, "Ch·ªß nh·∫≠t": 6
}
WEEK_START = WEEKDAY_MAP.get(week_start_label, 0)


    start_date = st.date_input(
        "T·ª´ ng√†y",
        df["Ng√†y"].min().date(),
        key=GEN_PREFIX + "start_date",
    )
    end_date = st.date_input(
        "ƒê·∫øn ng√†y",
        df["Ng√†y"].max().date(),
        key=GEN_PREFIX + "end_date",
    )

    # Lo·∫°i CT
    loaiCT_filter = ms_all(
        key=GEN_PREFIX + "loaiCT",
        label="Lo·∫°i CT",
        options=df["LoaiCT"] if "LoaiCT" in df.columns else [],
    )

    # Brand
    brand_filter = ms_all(
        key=GEN_PREFIX + "brand",
        label="Brand",
        options=df["Brand"] if "Brand" in df.columns else [],
    )

    # Cascade Region by Brand
    df_brand = df[df["Brand"].isin(brand_filter)] if (brand_filter and "Brand" in df.columns) else df.iloc[0:0]
    region_filter = ms_all(
        key=GEN_PREFIX + "region",
        label="Region",
        options=df_brand["Region"] if "Region" in df_brand.columns else [],
    )

    # Cascade Store by Brand + Region
    df_brand_region = df_brand[df_brand["Region"].isin(region_filter)] if (region_filter and "Region" in df_brand.columns) else df_brand.iloc[0:0]
    store_filter = ms_all(
        key=GEN_PREFIX + "store",
        label="C·ª≠a h√†ng",
        options=df_brand_region["ƒêi·ªÉm_mua_h√†ng"] if "ƒêi·ªÉm_mua_h√†ng" in df_brand_region.columns else [],
    )

# =====================================================
# APPLY FILTER
# =====================================================
mask = (df["Ng√†y"] >= pd.to_datetime(start_date)) & (df["Ng√†y"] <= pd.to_datetime(end_date))

if "LoaiCT" in df.columns:
    mask &= df["LoaiCT"].isin(loaiCT_filter if loaiCT_filter else [])

if "Brand" in df.columns:
    mask &= df["Brand"].isin(brand_filter if brand_filter else [])

if "Region" in df.columns:
    mask &= df["Region"].isin(region_filter if region_filter else [])

if "ƒêi·ªÉm_mua_h√†ng" in df.columns:
    mask &= df["ƒêi·ªÉm_mua_h√†ng"].isin(store_filter if store_filter else [])

df_f = df.loc[mask].copy()

if df_f.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu sau khi √°p b·ªô l·ªçc.")
    st.stop()

# =====================================================
# TIME COLUMN (TU·∫¶N ƒÇN THEO TH·ª® TU·ª≤ CH·ªåN)
# =====================================================
df_f_time = df_f.copy()

if time_type == "Ng√†y":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.date.astype(str)

elif time_type == "Tu·∫ßn":
    # ‚úÖ neo tu·∫ßn theo th·ª© ch·ªçn + label Tu·∫ßn WW/YYYY
    df_f_time["_WeekAnchor"] = week_anchor(df_f_time["Ng√†y"], WEEK_START)
    df_f_time["Time"] = week_label_from_anchor(df_f_time["_WeekAnchor"])

elif time_type == "Th√°ng":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("M").astype(str)

elif time_type == "Qu√Ω":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.to_period("Q").astype(str)

elif time_type == "NƒÉm":
    df_f_time["Time"] = df_f_time["Ng√†y"].dt.year.astype(str)

# =====================================================
# KPI
# =====================================================
gross = float(df_f["T·ªïng_Gross"].sum()) if "T·ªïng_Gross" in df_f.columns else 0
net = float(df_f["T·ªïng_Net"].sum()) if "T·ªïng_Net" in df_f.columns else 0
orders = df_f["S·ªë_CT"].nunique() if "S·ªë_CT" in df_f.columns else 0
customers = df_f["S·ªë_ƒëi·ªán_tho·∫°i"].nunique() if "S·ªë_ƒëi·ªán_tho·∫°i" in df_f.columns else 0
ck_rate = (1 - net / gross) * 100 if gross > 0 else 0

c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Gross", value=f"{gross:,.0f}")
c2.metric("Net", value=f"{net:,.0f}")
c3.metric("CK %", value=f"{ck_rate:.2f}%")
c4.metric("ƒê∆°n h√†ng", value=f"{orders:,}")
c5.metric("Kh√°ch h√†ng", value=f"{customers:,}")

# =====================================================
# TIME GROUP (TU·∫¶N: group theo anchor, KH√îNG resample('W'))
# =====================================================
def group_time(df_in: pd.DataFrame, tt: str, week_start: int) -> pd.DataFrame:
    if tt == "Tu·∫ßn":
        tmp = df_in.copy()
        tmp["_WeekAnchor"] = week_anchor(tmp["Ng√†y"], week_start)

        d = (
            tmp.groupby("_WeekAnchor", dropna=False)
            .agg(
                Gross=("T·ªïng_Gross", "sum"),
                Net=("T·ªïng_Net", "sum"),
                Orders=("S·ªë_CT", "nunique"),
                Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
            )
            .reset_index()
            .rename(columns={"_WeekAnchor": "Ng√†y"})
            .sort_values("Ng√†y")
        )
    else:
        freq_map = {"Ng√†y": "D", "Th√°ng": "ME", "Qu√Ω": "Q", "NƒÉm": "Y"}
        d = (
            df_in.set_index("Ng√†y")
            .resample(freq_map[tt])
            .agg(
                Gross=("T·ªïng_Gross", "sum"),
                Net=("T·ªïng_Net", "sum"),
                Orders=("S·ªë_CT", "nunique"),
                Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
            )
            .reset_index()
            .sort_values("Ng√†y")
        )

    d["CK_%"] = np.where(d["Gross"] > 0, (1 - d["Net"] / d["Gross"]) * 100, 0)
    d["Net_prev"] = d["Net"].shift(1)
    d["Growth_%"] = np.where(d["Net_prev"] > 0, (d["Net"] - d["Net_prev"]) / d["Net_prev"] * 100, 0)
    return d

df_time = group_time(df_f, time_type, WEEK_START)

st.subheader(f"‚è± Theo th·ªùi gian ({time_type})")
df_time_show = df_time.copy()

if time_type == "Tu·∫ßn":
    # ‚úÖ hi·ªÉn th·ªã d·∫°ng 'Tu·∫ßn WW/YYYY' cho b·∫£ng th·ªùi gian
    df_time_show["_label"] = week_label_from_anchor(df_time_show["Ng√†y"])
    df_time_show["Ng√†y"] = df_time_show["_label"]
    df_time_show = df_time_show.drop(columns=["_label"])
else:
    df_time_show["Ng√†y"] = pd.to_datetime(df_time_show["Ng√†y"], errors="coerce").dt.strftime("%Y-%m-%d")

for c in ["Gross", "Net", "Orders", "Customers", "Net_prev"]:
    if c in df_time_show.columns:
        df_time_show[c] = df_time_show[c].apply(fmt_int)

for c in ["CK_%", "Growth_%"]:
    if c in df_time_show.columns:
        df_time_show[c] = df_time_show[c].apply(lambda v: fmt_pct(v, 2, with_sign=(c == "Growth_%")))

st.dataframe(df_time_show, use_container_width=True, hide_index=True)

# =====================================================
# REGION + TIME
# =====================================================
def group_region_time(df_in: pd.DataFrame) -> pd.DataFrame:
    d = (
        df_in.groupby(["Time", "Region"], dropna=False)
        .agg(
            Gross=("T·ªïng_Gross", "sum"),
            Net=("T·ªïng_Net", "sum"),
            Orders=("S·ªë_CT", "nunique"),
            Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        )
        .reset_index()
    )
    d["CK_%"] = np.where(d["Gross"] > 0, (d["Gross"] - d["Net"]) / d["Gross"] * 100, 0)
    return d.sort_values(["Time", "Net"], ascending=[True, False])

df_region_time = group_region_time(df_f_time)

st.subheader(f"üåç Theo Region + {time_type}")
df_region_time_show = df_region_time.copy()
df_region_time_show["Time"] = df_region_time_show["Time"].astype(str)

for c in ["Gross", "Net", "Orders", "Customers"]:
    if c in df_region_time_show.columns:
        df_region_time_show[c] = df_region_time_show[c].apply(fmt_int)
if "CK_%" in df_region_time_show.columns:
    df_region_time_show["CK_%"] = df_region_time_show["CK_%"].apply(lambda v: fmt_pct(v, 2))

st.dataframe(df_region_time_show, use_container_width=True, hide_index=True)

# =====================================================
# STORE SUMMARY
# =====================================================
st.subheader("üè™ T·ªïng quan theo C·ª≠a h√†ng")

df_store = (
    df_f.groupby("ƒêi·ªÉm_mua_h√†ng", dropna=False)
    .agg(
        Gross=("T·ªïng_Gross", "sum"),
        Net=("T·ªïng_Net", "sum"),
        Orders=("S·ªë_CT", "nunique"),
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
    )
    .reset_index()
)

df_store["CK_%"] = np.where(df_store["Gross"] > 0, (df_store["Gross"] - df_store["Net"]) / df_store["Gross"] * 100, 0)

df_store_show = df_store.sort_values("Net", ascending=False).copy()
for c in ["Gross", "Net", "Orders", "Customers"]:
    df_store_show[c] = df_store_show[c].apply(fmt_int)
df_store_show["CK_%"] = df_store_show["CK_%"].apply(lambda v: fmt_pct(v, 2))

st.dataframe(df_store_show, use_container_width=True, hide_index=True)

# =====================================================
# PRODUCT SUMMARY
# =====================================================
st.subheader("üì¶ Theo Nh√≥m SP / M√£ NB")

df_product = df_f.copy()

col1, col2 = st.columns(2)
with col1:
    nhom_vals = sorted(df_product["Nh√≥m_h√†ng"].dropna().unique()) if "Nh√≥m_h√†ng" in df_product.columns else []
    nhom_sp_selected = st.multiselect("üì¶ Ch·ªçn Nh√≥m SP", nhom_vals, key=GEN_PREFIX + "nhom_sp")
with col2:
    ma_vals = sorted(df_product["M√£_NB"].dropna().unique()) if "M√£_NB" in df_product.columns else []
    ma_nb_selected = st.multiselect("üè∑Ô∏è Ch·ªçn M√£ NB", ma_vals, key=GEN_PREFIX + "ma_nb")

if nhom_sp_selected and "Nh√≥m_h√†ng" in df_product.columns:
    df_product = df_product[df_product["Nh√≥m_h√†ng"].isin(nhom_sp_selected)]
if ma_nb_selected and "M√£_NB" in df_product.columns:
    df_product = df_product[df_product["M√£_NB"].isin(ma_nb_selected)]

# NOTE: b·∫°n ƒëang d√πng Orders=("S·ªë_l∆∞·ª£ng","sum") => ch·ªâ ch·∫°y n·∫øu c√≥ c·ªôt S·ªë_l∆∞·ª£ng
# N·∫øu kh√¥ng c√≥, ƒë·ªïi l·∫°i S·ªë_CT nunique
if "S·ªë_l∆∞·ª£ng" in df_product.columns:
    orders_agg = ("S·ªë_l∆∞·ª£ng", "sum")
else:
    orders_agg = ("S·ªë_CT", "nunique")

df_product_group = (
    df_product.groupby("M√£_NB", dropna=False)
    .agg(
        Gross=("T·ªïng_Gross", "sum"),
        Net=("T·ªïng_Net", "sum"),
        Orders=orders_agg,
        Customers=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
    )
    .reset_index()
    .sort_values("Net", ascending=False)
)

df_product_show = df_product_group.copy()
for c in ["Gross", "Net", "Orders", "Customers"]:
    if c in df_product_show.columns:
        df_product_show[c] = df_product_show[c].apply(fmt_int)

st.dataframe(df_product_show, use_container_width=True, hide_index=True)
