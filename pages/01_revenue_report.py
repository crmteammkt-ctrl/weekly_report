import pandas as pd
import streamlit as st
import plotly.express as px

from load_data import get_active_data # d√πng chung d·ªØ li·ªáu Parquet

# =====================================================
# CONFIG
# =====================================================
st.set_page_config(page_title="üìà B√°o c√°o Doanh thu", layout="wide")
st.title("üìà B√°o c√°o Doanh thu")


# =====================================================
# L·∫§Y D·ªÆ LI·ªÜU HI·ªÜN H√ÄNH
# =====================================================
df = get_active_data()
st.sidebar.caption(
    "üîé ƒêang d√πng ngu·ªìn: **{}**".format(
        st.session_state.get("active_source", "default")
    )
)

df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
df = df.dropna(subset=["Ng√†y"])

if df.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch. Ki·ªÉm tra l·∫°i ngu·ªìn d·ªØ li·ªáu.")
    st.stop()



# =====================================================
# SIDEBAR FILTER (Brand ‚Üí Region ‚Üí C·ª≠a h√†ng ph·ª• thu·ªôc)
# =====================================================

# C√°c list ƒë·ªôc l·∫≠p
loaict_options   = sorted(df["LoaiCT"].dropna().unique())
checksdt_options = sorted(df["Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i"].dropna().unique())
checkten_options = sorted(df["Ki·ªÉm_tra_t√™n"].dropna().unique())

with st.sidebar:
    st.header("üéõ B·ªô l·ªçc d·ªØ li·ªáu")

    time_grain = st.selectbox(
        "Ph√¢n t√≠ch theo",
        ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω"],
        key="rev_time_grain",
    )

    start_date = st.date_input(
        "T·ª´ ng√†y",
        df["Ng√†y"].min().date(),
        key="rev_start_date",
    )
    end_date = st.date_input(
        "ƒê·∫øn ng√†y",
        df["Ng√†y"].max().date(),
        key="rev_end_date",
    )

    # ====== Brand (g·ªëc) ======
    brand_all = sorted(df["Brand"].dropna().unique())
    brand_raw = st.multiselect(
        "Brand",
        ["T·∫•t c·∫£"] + brand_all,
        default=["T·∫•t c·∫£"],
        key="rev_brand",
    )

    # Brand th·ª±c s·ª± ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ l·ªçc Region
    brand_selected = brand_all if (not brand_raw or "T·∫•t c·∫£" in brand_raw) else brand_raw
    df_for_region = df[df["Brand"].isin(brand_selected)]

    # ====== Region ph·ª• thu·ªôc Brand ======
    region_all = sorted(df_for_region["Region"].dropna().unique())
    region_raw = st.multiselect(
        "Region",
        ["T·∫•t c·∫£"] + region_all,
        default=["T·∫•t c·∫£"],
        key="rev_region",
    )

    region_selected = region_all if (not region_raw or "T·∫•t c·∫£" in region_raw) else region_raw
    df_for_store = df_for_region[df_for_region["Region"].isin(region_selected)]

    # ====== C·ª≠a h√†ng ph·ª• thu·ªôc Brand + Region ======
    store_all = sorted(df_for_store["ƒêi·ªÉm_mua_h√†ng"].dropna().unique())
    store_raw = st.multiselect(
        "ƒêi·ªÉm mua h√†ng",
        ["T·∫•t c·∫£"] + store_all,
        default=["T·∫•t c·∫£"],
        key="rev_store",
    )

    # ====== C√°c filter kh√°c (kh√¥ng ph·ª• thu·ªôc) ======
    loaict_raw = st.multiselect(
        "LoaiCT",
        ["T·∫•t c·∫£"] + loaict_options,
        default=["T·∫•t c·∫£"],
        key="rev_loaict",
    )
    checksdt_raw = st.multiselect(
        "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i",
        ["T·∫•t c·∫£"] + checksdt_options,
        default=["T·∫•t c·∫£"],
        key="rev_checksdt",
    )
    checkten_raw = st.multiselect(
        "Ki·ªÉm_tra_t√™n",
        ["T·∫•t c·∫£"] + checkten_options,
        default=["T·∫•t c·∫£"],
        key="rev_checkten",
    )

# ---------- H√†m x·ª≠ l√Ω "T·∫•t c·∫£" ----------
def clean_filter(values, all_values):
    if (not values) or ("T·∫•t c·∫£" in values):
        return all_values
    return values

brand_filter   = clean_filter(brand_raw,   brand_all)
region_filter  = clean_filter(region_raw,  region_all)
store_filter   = clean_filter(store_raw,   store_all)
loaict_filter  = clean_filter(loaict_raw,  loaict_options)
checksdt_filter = clean_filter(checksdt_raw, checksdt_options)
checkten_filter = clean_filter(checkten_raw, checkten_options)

# ---------- L·ªçc d·ªØ li·ªáu ----------
mask = (
    (df["Ng√†y"] >= pd.to_datetime(start_date))
    & (df["Ng√†y"] <= pd.to_datetime(end_date))
    & (df["Brand"].isin(brand_filter))
    & (df["Region"].isin(region_filter))
    & (df["ƒêi·ªÉm_mua_h√†ng"].isin(store_filter))
    & (df["LoaiCT"].isin(loaict_filter))
    & (df["Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i"].isin(checksdt_filter))
    & (df["Ki·ªÉm_tra_t√™n"].isin(checkten_filter))
)

df_filtered = df.loc[mask].copy()

# =====================================================
# HELPER FUNCTIONS
# =====================================================
def add_time_key(df_in: pd.DataFrame, grain: str):
    """Th√™m c·ªôt Key + Year ƒë·ªÉ gom theo Ng√†y/Tu·∫ßn/Th√°ng/Qu√Ω."""
    df_out = df_in.copy()
    if grain == "Ng√†y":
        df_out["Key"] = df_out["Ng√†y"].dt.date
        df_out["Year"] = df_out["Ng√†y"].dt.year
        group_cols = ["Key"]
    else:
        df_out["Year"] = df_out["Ng√†y"].dt.year
        if grain == "Tu·∫ßn":
            df_out["Key"] = df_out["Ng√†y"].dt.isocalendar().week
        elif grain == "Th√°ng":
            df_out["Key"] = df_out["Ng√†y"].dt.month
        elif grain == "Qu√Ω":
            df_out["Key"] = df_out["Ng√†y"].dt.quarter
        group_cols = ["Year", "Key"]
    return df_out, group_cols


def summarize_revenue(df_in: pd.DataFrame, grain: str) -> pd.DataFrame:
    """T·ªïng h·ª£p Gross/Net/S·ªë KH/S·ªë ƒêH + so s√°nh k·ª≥ tr∆∞·ªõc."""
    if df_in.empty:
        return pd.DataFrame()

    df_tmp, group_cols = add_time_key(df_in, grain)

    summary = (
        df_tmp.groupby(group_cols)
        .agg(
            T·ªïng_Gross=("T·ªïng_Gross", "sum"),
            T·ªïng_Net=("T·ªïng_Net", "sum"),
            S·ªë_KH=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
            S·ªë_ƒë∆°n_h√†ng=("S·ªë_CT", "nunique"),
        )
        .reset_index()
    )

    summary["T·ª∑_l·ªá_CK (%)"] = (
        100 * (1 - summary["T·ªïng_Net"] / summary["T·ªïng_Gross"])
    ).where(summary["T·ªïng_Gross"] != 0, 0)

    summary = summary.sort_values(group_cols)

    for col in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng"]:
        prev_col = f"Prev_{col}"
        pct_col = f"%_So_s√°nh_{col}"
        summary[prev_col] = summary[col].shift(1)
        summary[pct_col] = (
            (summary[col] - summary[prev_col]) / summary[prev_col] * 100
        ).where(summary[prev_col].notna() & (summary[prev_col] != 0))

    return summary


def top_bottom_store(df_in: pd.DataFrame, grain: str, top: bool = True) -> pd.DataFrame:
    """Top/Bottom 10 ƒêi·ªÉm_mua_h√†ng theo T·ªïng_Net ·ªü k·ª≥ m·ªõi nh·∫•t."""
    if df_in.empty:
        return pd.DataFrame()

    df_store, group_cols = add_time_key(df_in, grain)
    group_cols_store = ["ƒêi·ªÉm_mua_h√†ng"] + group_cols

    grouped = (
        df_store.groupby(group_cols_store, as_index=False)[["T·ªïng_Gross", "T·ªïng_Net"]]
        .sum()
    )
    grouped["T·ª∑_l·ªá_CK (%)"] = (
        100 * (1 - grouped["T·ªïng_Net"] / grouped["T·ªïng_Gross"])
    ).where(grouped["T·ªïng_Gross"] != 0, 0)

    grouped = grouped.sort_values(["ƒêi·ªÉm_mua_h√†ng"] + group_cols)
    grouped["Prev"] = grouped.groupby("ƒêi·ªÉm_mua_h√†ng")["T·ªïng_Net"].shift(1)
    grouped["Change%"] = (
        (grouped["T·ªïng_Net"] - grouped["Prev"]) / grouped["Prev"] * 100
    ).where(grouped["Prev"].notna() & (grouped["Prev"] != 0))

    # L·∫•y k·ª≥ m·ªõi nh·∫•t
    if grain == "Ng√†y":
        latest_key = grouped["Key"].max()
        latest_mask = grouped["Key"] == latest_key
    else:
        latest_year = grouped["Year"].max()
        latest_key = grouped.query("Year == @latest_year")["Key"].max()
        latest_mask = (grouped["Year"] == latest_year) & (grouped["Key"] == latest_key)

    latest = grouped.loc[latest_mask].copy()
    latest = latest.sort_values("T·ªïng_Net", ascending=not top).head(10)
    return latest


# =====================================================
# DATA VIEW
# =====================================================
st.subheader("üìë D·ªØ li·ªáu ƒë√£ l·ªçc")
st.dataframe(df_filtered, width="stretch")

# =====================================================
# SUMMARY TABLE
# =====================================================
st.subheader("üìä T·ªïng h·ª£p doanh thu")

df_summary = summarize_revenue(df_filtered, time_grain)

if df_summary.empty:
    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi l·ªçc.")
else:
    st.data_editor(
        df_summary,
        width="stretch",
        hide_index=True,
        column_config={
            "T·ªïng_Gross": st.column_config.NumberColumn("Gross", format="%.0f"),
            "T·ªïng_Net": st.column_config.NumberColumn("Net", format="%.0f"),
            "S·ªë_KH": st.column_config.NumberColumn("S·ªë KH", format="%.0f"),
            "S·ªë_ƒë∆°n_h√†ng": st.column_config.NumberColumn("S·ªë ƒêH", format="%.0f"),
            "T·ª∑_l·ªá_CK (%)": st.column_config.NumberColumn(
                "T·ª∑ l·ªá CK (%)", format="%.2f"
            ),
        },
    )

    fig = px.line(
        df_summary,
        x="Key",
        y=["T·ªïng_Gross", "T·ªïng_Net"],
        markers=True,
        title=f"Doanh thu theo {time_grain}",
    )
    st.plotly_chart(fig, width="stretch")

# =====================================================
# REGION REPORT
# =====================================================
st.subheader("üåç Doanh thu theo Region")

if df_filtered.empty:
    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi l·ªçc.")
else:
    df_region, group_cols = add_time_key(df_filtered, time_grain)
    group_cols_region = ["Region"] + group_cols

    grouped_region = (
        df_region.groupby(group_cols_region, as_index=False)
        .agg(
            T·ªïng_Gross=("T·ªïng_Gross", "sum"),
            T·ªïng_Net=("T·ªïng_Net", "sum"),
            S·ªë_KH=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
            S·ªë_ƒë∆°n_h√†ng=("S·ªë_CT", "nunique"),
        )
    )

    grouped_region["T·ª∑_l·ªá_CK (%)"] = (
        100 * (1 - grouped_region["T·ªïng_Net"] / grouped_region["T·ªïng_Gross"])
    ).where(grouped_region["T·ªïng_Gross"] != 0, 0)

    grouped_region = grouped_region.sort_values(["Region"] + group_cols_region[1:])
    for col in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng"]:
        prev_col = f"Prev_{col}"
        pct_col = f"%_So_s√°nh_{col}"
        grouped_region[prev_col] = grouped_region.groupby("Region")[col].shift(1)
        grouped_region[pct_col] = (
            (grouped_region[col] - grouped_region[prev_col])
            / grouped_region[prev_col]
            * 100
        ).where(
            grouped_region[prev_col].notna()
            & (grouped_region[prev_col] != 0)
        )

    if time_grain == "Ng√†y":
        latest_key = grouped_region["Key"].max()
        latest_mask = grouped_region["Key"] == latest_key
    else:
        latest_year = grouped_region["Year"].max()
        latest_key = grouped_region.query("Year == @latest_year")["Key"].max()
        latest_mask = (grouped_region["Year"] == latest_year) & (
            grouped_region["Key"] == latest_key
        )

    df_region_latest = grouped_region.loc[latest_mask].copy()

    st.data_editor(
        df_region_latest,
        width="stretch",
        hide_index=True,
        column_config={
            "T·ªïng_Gross": st.column_config.NumberColumn("Gross", format="%.0f"),
            "T·ªïng_Net": st.column_config.NumberColumn("Net", format="%.0f"),
            "S·ªë_KH": st.column_config.NumberColumn("S·ªë KH", format="%.0f"),
            "S·ªë_ƒë∆°n_h√†ng": st.column_config.NumberColumn("S·ªë ƒêH", format="%.0f"),
            "T·ª∑_l·ªá_CK (%)": st.column_config.NumberColumn(
                "T·ª∑ l·ªá CK (%)", format="%.2f"
            ),
        },
    )

# =====================================================
# STORE TOP / BOTTOM
# =====================================================
st.subheader("üè™ Top/Bottom 10 ƒêi·ªÉm mua h√†ng")

df_top10 = top_bottom_store(df_filtered, time_grain, top=True)
df_bottom10 = top_bottom_store(df_filtered, time_grain, top=False)

col1, col2 = st.columns(2)

with col1:
    st.markdown("### üèÜ Top 10 ƒêi·ªÉm mua h√†ng")
    if df_top10.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
    else:
        st.data_editor(
            df_top10,
            width="stretch",
            hide_index=True,
            column_config={
                "T·ªïng_Gross": st.column_config.NumberColumn(
                    "Gross", format="%.0f"
                ),
                "T·ªïng_Net": st.column_config.NumberColumn("Net", format="%.0f"),
                "T·ª∑_l·ªá_CK (%)": st.column_config.NumberColumn(
                    "T·ª∑ l·ªá CK (%)", format="%.2f"
                ),
                "Prev": st.column_config.NumberColumn(
                    "Net k·ª≥ tr∆∞·ªõc", format="%.0f"
                ),
                "Change%": st.column_config.NumberColumn(
                    "TƒÉng/gi·∫£m (%)", format="%.2f"
                ),
            },
        )

with col2:
    st.markdown("### üìâ Bottom 10 ƒêi·ªÉm mua h√†ng")
    if df_bottom10.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
    else:
        st.data_editor(
            df_bottom10,
            width="stretch",
            hide_index=True,
            column_config={
                "T·ªïng_Gross": st.column_config.NumberColumn(
                    "Gross", format="%.0f"
                ),
                "T·ªïng_Net": st.column_config.NumberColumn("Net", format="%.0f"),
                "T·ª∑_l·ªá_CK (%)": st.column_config.NumberColumn(
                    "T·ª∑ l·ªá CK (%)", format="%.2f"
                ),
                "Prev": st.column_config.NumberColumn(
                    "Net k·ª≥ tr∆∞·ªõc", format="%.0f"
                ),
                "Change%": st.column_config.NumberColumn(
                    "TƒÉng/gi·∫£m (%)", format="%.2f"
                ),
            },
        )
