# pages/01_revenue_report.py
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px

from load_data import get_active_data

# =====================================================
# FORMAT HELPERS (an to√†n - kh√¥ng ph·ª• thu·ªôc Streamlit version)
# =====================================================
def fmt_int(x):
    if pd.isna(x):
        return ""
    try:
        return f"{float(x):,.0f}"
    except Exception:
        return ""

def fmt_pct(x, decimals=2, with_sign=False):
    # x ƒëang l√† 20.8 nghƒ©a l√† 20.8%
    if pd.isna(x):
        return ""
    try:
        v = float(x)
        s = f"{v:,.{decimals}f}%"
        if with_sign and v > 0:
            s = "+" + s
        return s
    except Exception:
        return ""

def ensure_datetime(df: pd.DataFrame) -> pd.DataFrame:
    if "Ng√†y" in df.columns:
        df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
        df = df.dropna(subset=["Ng√†y"])
    return df

def fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for c in ["T·ªïng_Gross", "T·ªïng_Net"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def show_df(df_show: pd.DataFrame, title: str | None = None):
    if title:
        st.subheader(title)
    st.dataframe(df_show, use_container_width=True, hide_index=True)

# =====================================================
# FILTER HELPERS (G·ªåN + LINH HO·∫†T + ALL + RESET)
# =====================================================
REV_PREFIX = "rev_"

def reset_by_prefix(prefix: str):
    for k in list(st.session_state.keys()):
        if k.startswith(prefix):
            st.session_state.pop(k, None)
    st.rerun()

def ms_all(key: str, label: str, options, all_label="All", default_all=True):
    """
    Multiselect c√≥ All:
    - options ƒë·ªïi kh√¥ng crash
    - selection c≈© ƒë∆∞·ª£c gi·ªØ n·∫øu c√≤n h·ª£p l·ªá
    - tr·∫£ v·ªÅ list gi√° tr·ªã th·∫≠t ƒë·ªÉ filter (kh√¥ng g·ªìm All)
    """
    opts = pd.Series(list(options)).dropna().astype(str).str.strip()
    opts = sorted(opts.unique().tolist())
    ui_opts = [all_label] + opts

    # init BEFORE widget
    if key not in st.session_state:
        st.session_state[key] = [all_label] if default_all else (opts[:1] if opts else [all_label])

    # sanitize BEFORE widget
    cur = [str(x).strip() for x in st.session_state.get(key, []) if str(x).strip() in ui_opts]
    if not cur:
        cur = [all_label] if default_all else (opts[:1] if opts else [all_label])
        st.session_state[key] = cur

    selected = st.multiselect(label, options=ui_opts, key=key)

    if (not selected) or (all_label in selected):
        return opts
    return [x for x in selected if x in opts]

# =====================================================
# WEEK HELPERS (TU·∫¶N B·∫ÆT ƒê·∫¶U THEO TH·ª® L·∫§Y T·ª™ GENERAL)
# =====================================================
WEEKDAY_MAP = {
    "Th·ª© 2": 0, "Th·ª© 3": 1, "Th·ª© 4": 2, "Th·ª© 5": 3,
    "Th·ª© 6": 4, "Th·ª© 7": 5, "Ch·ªß nh·∫≠t": 6
}
# l·∫•y l·ª±a ch·ªçn t·ª´ General: key="gen_week_start"
week_label = st.session_state.get("gen_week_start", "Th·ª© 2")
WEEK_START = WEEKDAY_MAP.get(week_label, 0)

def week_anchor(dt: pd.Series, week_start: int) -> pd.Series:
    """
    Tr·∫£ v·ªÅ ng√†y neo c·ªßa tu·∫ßn theo week_start (0=Mon ... 6=Sun)
    """
    d = pd.to_datetime(dt)
    return (d - pd.to_timedelta((d.dt.weekday - week_start) % 7, unit="D")).dt.normalize()

# =====================================================
# CONFIG
# =====================================================
st.set_page_config(page_title="üìà B√°o c√°o Doanh thu", layout="wide")
st.title("üìà B√°o c√°o Doanh thu")

# =====================================================
# LOAD
# =====================================================
df = get_active_data()
st.sidebar.caption("üîé ƒêang d√πng ngu·ªìn: **{}**".format(st.session_state.get("active_source", "default")))

df = ensure_datetime(df)
df = fix_numeric(df)

if df.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch. Ki·ªÉm tra l·∫°i ngu·ªìn d·ªØ li·ªáu.")
    st.stop()

# =====================================================
# SIDEBAR FILTER (G·ªåN + ALL + CASCADING + RESET)
# =====================================================
with st.sidebar:
    st.header("üéõ B·ªô l·ªçc d·ªØ li·ªáu")

    # Reset filters for Revenue page
    if st.button("üîÑ Reset b·ªô l·ªçc (Revenue)", use_container_width=True):
        reset_by_prefix(REV_PREFIX)

    time_grain = st.selectbox(
        "Ph√¢n t√≠ch theo",
        ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω"],
        key=REV_PREFIX + "time_grain",
    )

    # (tu·ª≥ ch·ªçn) ch·ªâ ƒë·ªÉ user bi·∫øt ƒëang l·∫•y tu·∫ßn theo th·ª© n√†o
    if time_grain == "Tu·∫ßn":
        st.caption(f"üìå Tu·∫ßn ƒëang b·∫Øt ƒë·∫ßu t·ª´: **{week_label}** (l·∫•y t·ª´ General)")

    start_date = st.date_input(
        "T·ª´ ng√†y",
        df["Ng√†y"].min().date(),
        key=REV_PREFIX + "start_date",
    )
    end_date = st.date_input(
        "ƒê·∫øn ng√†y",
        df["Ng√†y"].max().date(),
        key=REV_PREFIX + "end_date",
    )

    # Lo·∫°i CT
    loaict_filter = ms_all(
        key=REV_PREFIX + "loaict",
        label="LoaiCT",
        options=df["LoaiCT"] if "LoaiCT" in df.columns else [],
    )

    # Brand
    brand_filter = ms_all(
        key=REV_PREFIX + "brand",
        label="Brand",
        options=df["Brand"] if "Brand" in df.columns else [],
    )

    # Cascade: Region theo Brand
    df_b = df[df["Brand"].isin(brand_filter)] if (brand_filter and "Brand" in df.columns) else df.iloc[0:0]
    region_filter = ms_all(
        key=REV_PREFIX + "region",
        label="Region",
        options=df_b["Region"] if "Region" in df_b.columns else [],
    )

    # Cascade: Store theo Brand + Region
    df_br = df_b[df_b["Region"].isin(region_filter)] if (region_filter and "Region" in df_b.columns) else df_b.iloc[0:0
    ]
    store_filter = ms_all(
        key=REV_PREFIX + "store",
        label="ƒêi·ªÉm mua h√†ng",
        options=df_br["ƒêi·ªÉm_mua_h√†ng"] if "ƒêi·ªÉm_mua_h√†ng" in df_br.columns else [],
    )

    # Check SƒêT
    checksdt_filter = ms_all(
        key=REV_PREFIX + "checksdt",
        label="Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i",
        options=df["Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i"] if "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i" in df.columns else [],
    )

    # Ki·ªÉm tra t√™n
    checkten_filter = ms_all(
        key=REV_PREFIX + "checkten",
        label="Ki·ªÉm_tra_t√™n",
        options=df["Ki·ªÉm_tra_t√™n"] if "Ki·ªÉm_tra_t√™n" in df.columns else [],
    )

# =====================================================
# APPLY FILTER
# =====================================================
mask = (df["Ng√†y"] >= pd.to_datetime(start_date)) & (df["Ng√†y"] <= pd.to_datetime(end_date))

if "LoaiCT" in df.columns:
    mask &= df["LoaiCT"].isin(loaict_filter if loaict_filter else [])
if "Brand" in df.columns:
    mask &= df["Brand"].isin(brand_filter if brand_filter else [])
if "Region" in df.columns:
    mask &= df["Region"].isin(region_filter if region_filter else [])
if "ƒêi·ªÉm_mua_h√†ng" in df.columns:
    mask &= df["ƒêi·ªÉm_mua_h√†ng"].isin(store_filter if store_filter else [])
if "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i" in df.columns:
    mask &= df["Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i"].isin(checksdt_filter if checksdt_filter else [])
if "Ki·ªÉm_tra_t√™n" in df.columns:
    mask &= df["Ki·ªÉm_tra_t√™n"].isin(checkten_filter if checkten_filter else [])

df_filtered = df.loc[mask].copy()

if df_filtered.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu sau khi √°p b·ªô l·ªçc.")
    st.stop()

# =====================================================
# HELPER: TIME KEY (TU·∫¶N THEO TH·ª® TU·ª≤ CH·ªåN)
# =====================================================
def add_time_key(df_in: pd.DataFrame, grain: str):
    df_out = df_in.copy()

    if grain == "Ng√†y":
        df_out["Key"] = df_out["Ng√†y"].dt.date  # datetime.date
        df_out["Year"] = df_out["Ng√†y"].dt.year
        group_cols = ["Key"]

    else:
        if grain == "Tu·∫ßn":
            # ‚úÖ custom tu·∫ßn theo th·ª© ch·ªçn
            df_out["_WeekAnchor"] = week_anchor(df_out["Ng√†y"], WEEK_START)
            iso = df_out["_WeekAnchor"].dt.isocalendar()
            df_out["Year"] = iso["year"].astype(int)
            df_out["Key"] = iso["week"].astype(int)
        elif grain == "Th√°ng":
            df_out["Year"] = df_out["Ng√†y"].dt.year
            df_out["Key"] = df_out["Ng√†y"].dt.month.astype(int)
        elif grain == "Qu√Ω":
            df_out["Year"] = df_out["Ng√†y"].dt.year
            df_out["Key"] = df_out["Ng√†y"].dt.quarter.astype(int)

        group_cols = ["Year", "Key"]

    return df_out, group_cols

# =====================================================
# SUMMARY TABLE
# =====================================================
def summarize_revenue(df_in: pd.DataFrame, grain: str) -> pd.DataFrame:
    if df_in.empty:
        return pd.DataFrame()

    df_tmp, group_cols = add_time_key(df_in, grain)

    summary = (
        df_tmp.groupby(group_cols)
        .agg(
            T·ªïng_Gross=("T·ªïng_Gross", "sum"),
            T·ªïng_Net=("T·ªïng_Net", "sum"),
            S·ªë_KH=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
            S·ªë_ƒë∆°n_h√†ng=("S·ªë_CT", "nunique"),
        )
        .reset_index()
    )

    summary["T·ª∑_l·ªá_CK (%)"] = (100 * (1 - summary["T·ªïng_Net"] / summary["T·ªïng_Gross"])).where(
        summary["T·ªïng_Gross"] != 0, 0
    )

    summary = summary.sort_values(group_cols)

    for col in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng"]:
        prev_col = f"Prev_{col}"
        pct_col = f"%_So_s√°nh_{col}"
        summary[prev_col] = summary[col].shift(1)
        summary[pct_col] = ((summary[col] - summary[prev_col]) / summary[prev_col] * 100).where(
            summary[prev_col].notna() & (summary[prev_col] != 0)
        )

    return summary

# =====================================================
# TOP/BOTTOM STORE (l·ªçc theo k·ª≥ ƒë∆∞·ª£c ch·ªçn)
# =====================================================
def top_bottom_store(df_in: pd.DataFrame, grain: str, top: bool = True, year=None, key=None) -> pd.DataFrame:
    if df_in.empty:
        return pd.DataFrame()

    df_store, group_cols = add_time_key(df_in, grain)
    group_cols_store = ["ƒêi·ªÉm_mua_h√†ng"] + group_cols

    grouped = df_store.groupby(group_cols_store, as_index=False)[["T·ªïng_Gross", "T·ªïng_Net"]].sum()

    grouped["T·ª∑_l·ªá_CK (%)"] = (100 * (1 - grouped["T·ªïng_Net"] / grouped["T·ªïng_Gross"])).where(
        grouped["T·ªïng_Gross"] != 0, 0
    )

    grouped = grouped.sort_values(["ƒêi·ªÉm_mua_h√†ng"] + group_cols)
    grouped["Prev"] = grouped.groupby("ƒêi·ªÉm_mua_h√†ng")["T·ªïng_Net"].shift(1)
    grouped["Change%"] = ((grouped["T·ªïng_Net"] - grouped["Prev"]) / grouped["Prev"] * 100).where(
        grouped["Prev"].notna() & (grouped["Prev"] != 0)
    )

    if grain == "Ng√†y":
        sel_key = key if key is not None else grouped["Key"].max()
        mask2 = grouped["Key"] == sel_key
    else:
        if (year is None) or (key is None):
            sel_year = grouped["Year"].max()
            sel_key = grouped.query("Year == @sel_year")["Key"].max()
        else:
            sel_year = year
            sel_key = key
        mask2 = (grouped["Year"] == sel_year) & (grouped["Key"] == sel_key)

    out = grouped.loc[mask2].copy()
    out = out.sort_values("T·ªïng_Net", ascending=not top).head(10)
    return out

# =====================================================
# VIEW: RAW FILTERED (tu·ª≥ ch·ªçn)
# =====================================================
with st.expander("üìë Xem d·ªØ li·ªáu ƒë√£ l·ªçc (m·ªü/ƒë√≥ng)", expanded=False):
    st.dataframe(df_filtered, use_container_width=True)

# =====================================================
# SUMMARY DISPLAY + CHART
# =====================================================
st.subheader("üìä T·ªïng h·ª£p doanh thu")
df_summary = summarize_revenue(df_filtered, time_grain)

if df_summary.empty:
    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi l·ªçc.")
    st.stop()

# T·∫°o c·ªôt label hi·ªÉn th·ªã ƒë·∫πp
df_summary_show = df_summary.copy()

if time_grain == "Ng√†y":
    df_summary_show["K·ª≥"] = pd.to_datetime(df_summary_show["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
else:
    if time_grain == "Tu·∫ßn":
        df_summary_show["K·ª≥"] = df_summary_show.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        df_summary_show["K·ª≥"] = df_summary_show.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:  # Qu√Ω
        df_summary_show["K·ª≥"] = df_summary_show.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

# Format s·ªë b·∫±ng Python
for c in [
    "T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng",
    "Prev_T·ªïng_Gross", "Prev_T·ªïng_Net", "Prev_S·ªë_KH", "Prev_S·ªë_ƒë∆°n_h√†ng"
]:
    if c in df_summary_show.columns:
        df_summary_show[c] = df_summary_show[c].apply(fmt_int)

for c in [
    "T·ª∑_l·ªá_CK (%)",
    "%_So_s√°nh_T·ªïng_Gross", "%_So_s√°nh_T·ªïng_Net", "%_So_s√°nh_S·ªë_KH", "%_So_s√°nh_S·ªë_ƒë∆°n_h√†ng"
]:
    if c in df_summary_show.columns:
        df_summary_show[c] = df_summary_show[c].apply(lambda v: fmt_pct(v, 2, with_sign=c.startswith("%_So_s√°nh")))

# Hi·ªÉn th·ªã b·∫£ng summary
show_cols = ["K·ª≥"]
for c in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng", "T·ª∑_l·ªá_CK (%)", "Prev_T·ªïng_Net", "%_So_s√°nh_T·ªïng_Net"]:
    if c in df_summary_show.columns:
        show_cols.append(c)

show_df(df_summary_show[show_cols], title=None)

# Chart (plotly) d√πng d·ªØ li·ªáu g·ªëc (ch∆∞a format)
fig = px.line(
    df_summary,
    x="Key",
    y=["T·ªïng_Gross", "T·ªïng_Net"],
    markers=True,
    title=f"Doanh thu theo {time_grain}",
)
st.plotly_chart(fig, use_container_width=True)

# =====================================================
# REGION REPORT + FILTER "CH·ªåN K·ª≤"
# =====================================================
st.subheader("üåç Doanh thu theo Region")

df_region, group_cols = add_time_key(df_filtered, time_grain)
group_cols_region = ["Region"] + group_cols

grouped_region = (
    df_region.groupby(group_cols_region, as_index=False)
    .agg(
        T·ªïng_Gross=("T·ªïng_Gross", "sum"),
        T·ªïng_Net=("T·ªïng_Net", "sum"),
        S·ªë_KH=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        S·ªë_ƒë∆°n_h√†ng=("S·ªë_CT", "nunique"),
    )
)

grouped_region["T·ª∑_l·ªá_CK (%)"] = (100 * (1 - grouped_region["T·ªïng_Net"] / grouped_region["T·ªïng_Gross"])).where(
    grouped_region["T·ªïng_Gross"] != 0, 0
)

# So s√°nh k·ª≥ tr∆∞·ªõc theo t·ª´ng Region
grouped_region = grouped_region.sort_values(["Region"] + group_cols)
for col in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng"]:
    prev_col = f"Prev_{col}"
    pct_col = f"%_So_s√°nh_{col}"
    grouped_region[prev_col] = grouped_region.groupby("Region")[col].shift(1)
    grouped_region[pct_col] = ((grouped_region[col] - grouped_region[prev_col]) / grouped_region[prev_col] * 100).where(
        grouped_region[prev_col].notna() & (grouped_region[prev_col] != 0)
    )

# ====== Ch·ªçn k·ª≥ ƒë·ªÉ xem Region
st.markdown("### üîç Ch·ªçn k·ª≥ ƒë·ªÉ xem b·∫£ng Region")

if time_grain == "Ng√†y":
    periods = df_summary[["Key"]].drop_duplicates().sort_values("Key").copy()
    periods["label"] = pd.to_datetime(periods["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
    sel_label = st.selectbox(
        "K·ª≥ (Ng√†y)",
        periods["label"].tolist(),
        index=len(periods) - 1,
        key=REV_PREFIX + "region_period",
    )
    sel_key = periods.loc[periods["label"] == sel_label, "Key"].iloc[0]
    region_mask = grouped_region["Key"] == sel_key
else:
    periods = df_summary[["Year", "Key"]].drop_duplicates().sort_values(["Year", "Key"]).copy()
    if time_grain == "Tu·∫ßn":
        periods["label"] = periods.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        periods["label"] = periods.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:
        periods["label"] = periods.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

    sel_label = st.selectbox(
        "K·ª≥",
        periods["label"].tolist(),
        index=len(periods) - 1,
        key=REV_PREFIX + "region_period",
    )
    row = periods.loc[periods["label"] == sel_label].iloc[0]
    sel_year = int(row["Year"])
    sel_key = int(row["Key"])
    region_mask = (grouped_region["Year"] == sel_year) & (grouped_region["Key"] == sel_key)

df_region_view = grouped_region.loc[region_mask].copy().sort_values("T·ªïng_Net", ascending=False)

# Format hi·ªÉn th·ªã Region
df_region_show = df_region_view.copy()
if time_grain == "Ng√†y":
    df_region_show["K·ª≥"] = pd.to_datetime(df_region_show["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
else:
    if time_grain == "Tu·∫ßn":
        df_region_show["K·ª≥"] = df_region_show.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        df_region_show["K·ª≥"] = df_region_show.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:
        df_region_show["K·ª≥"] = df_region_show.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

for c in [
    "T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng",
    "Prev_T·ªïng_Gross", "Prev_T·ªïng_Net", "Prev_S·ªë_KH", "Prev_S·ªë_ƒë∆°n_h√†ng"
]:
    if c in df_region_show.columns:
        df_region_show[c] = df_region_show[c].apply(fmt_int)

for c in ["T·ª∑_l·ªá_CK (%)", "%_So_s√°nh_T·ªïng_Gross", "%_So_s√°nh_T·ªïng_Net", "%_So_s√°nh_S·ªë_KH", "%_So_s√°nh_S·ªë_ƒë∆°n_h√†ng"]:
    if c in df_region_show.columns:
        df_region_show[c] = df_region_show[c].apply(lambda v: fmt_pct(v, 2, with_sign=c.startswith("%_So_s√°nh")))

region_cols = [
    "K·ª≥", "Region", "T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng",
    "T·ª∑_l·ªá_CK (%)", "Prev_T·ªïng_Net", "%_So_s√°nh_T·ªïng_Net"
]
region_cols = [c for c in region_cols if c in df_region_show.columns]
show_df(df_region_show[region_cols], title=None)

# =====================================================
# STORE TOP / BOTTOM + FILTER "CH·ªåN K·ª≤"
# =====================================================
st.subheader("üè™ Top/Bottom 10 ƒêi·ªÉm mua h√†ng")

st.markdown("### üîç Ch·ªçn k·ª≥ ƒë·ªÉ xem Top/Bottom")
if time_grain == "Ng√†y":
    period_df = df_summary[["Key"]].drop_duplicates().sort_values("Key").copy()
    period_df["label"] = pd.to_datetime(period_df["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
    sel_label2 = st.selectbox(
        "K·ª≥ (Ng√†y)",
        period_df["label"].tolist(),
        index=len(period_df) - 1,
        key=REV_PREFIX + "store_period",
    )
    sel_key2 = period_df.loc[period_df["label"] == sel_label2, "Key"].iloc[0]
    top10 = top_bottom_store(df_filtered, time_grain, top=True, key=sel_key2)
    bottom10 = top_bottom_store(df_filtered, time_grain, top=False, key=sel_key2)
else:
    period_df = df_summary[["Year", "Key"]].drop_duplicates().sort_values(["Year", "Key"]).copy()
    if time_grain == "Tu·∫ßn":
        period_df["label"] = period_df.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        period_df["label"] = period_df.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:
        period_df["label"] = period_df.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

    sel_label2 = st.selectbox(
        "K·ª≥",
        period_df["label"].tolist(),
        index=len(period_df) - 1,
        key=REV_PREFIX + "store_period",
    )
    row2 = period_df.loc[period_df["label"] == sel_label2].iloc[0]
    sel_year2 = int(row2["Year"])
    sel_key2 = int(row2["Key"])
    top10 = top_bottom_store(df_filtered, time_grain, top=True, year=sel_year2, key=sel_key2)
    bottom10 = top_bottom_store(df_filtered, time_grain, top=False, year=sel_year2, key=sel_key2)

def format_store_table(dfin: pd.DataFrame) -> pd.DataFrame:
    if dfin.empty:
        return dfin
    out = dfin.copy()

    if time_grain == "Ng√†y":
        out["K·ª≥"] = pd.to_datetime(out["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
    else:
        if time_grain == "Tu·∫ßn":
            out["K·ª≥"] = out.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
        elif time_grain == "Th√°ng":
            out["K·ª≥"] = out.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
        else:
            out["K·ª≥"] = out.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

    for c in ["T·ªïng_Gross", "T·ªïng_Net", "Prev"]:
        if c in out.columns:
            out[c] = out[c].apply(fmt_int)

    if "T·ª∑_l·ªá_CK (%)" in out.columns:
        out["T·ª∑_l·ªá_CK (%)"] = out["T·ª∑_l·ªá_CK (%)"].apply(lambda v: fmt_pct(v, 2))
    if "Change%" in out.columns:
        out["Change%"] = out["Change%"].apply(lambda v: fmt_pct(v, 2, with_sign=True))

    cols = ["K·ª≥", "ƒêi·ªÉm_mua_h√†ng", "T·ªïng_Gross", "T·ªïng_Net", "T·ª∑_l·ªá_CK (%)", "Prev", "Change%"]
    cols = [c for c in cols if c in out.columns]
    return out[cols]

top10_show = format_store_table(top10)
bottom10_show = format_store_table(bottom10)

colA, colB = st.columns(2)
with colA:
    st.markdown("### üèÜ Top 10 ƒêi·ªÉm mua h√†ng")
    if top10_show.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
    else:
        st.dataframe(top10_show, use_container_width=True, hide_index=True)

with colB:
    st.markdown("### üìâ Bottom 10 ƒêi·ªÉm mua h√†ng")
    if bottom10_show.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
    else:
        st.dataframe(bottom10_show, use_container_width=True, hide_index=True)
