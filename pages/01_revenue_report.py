# pages/01_revenue_report.py
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px

from load_data import get_active_data

# =====================================================
# FORMAT HELPERS (an to√†n - kh√¥ng ph·ª• thu·ªôc Streamlit version)
# =====================================================
def fmt_int(x):
    if pd.isna(x):
        return ""
    try:
        return f"{float(x):,.0f}"
    except:
        return ""

def fmt_pct(x, decimals=2, with_sign=False):
    # x ƒëang l√† 20.8 nghƒ©a l√† 20.8%
    if pd.isna(x):
        return ""
    try:
        v = float(x)
        s = f"{v:,.{decimals}f}%"
        if with_sign and v > 0:
            s = "+" + s
        return s
    except:
        return ""

def ensure_datetime(df: pd.DataFrame) -> pd.DataFrame:
    if "Ng√†y" in df.columns:
        df["Ng√†y"] = pd.to_datetime(df["Ng√†y"], errors="coerce")
        df = df.dropna(subset=["Ng√†y"])
    return df

def fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for c in ["T·ªïng_Gross", "T·ªïng_Net"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def show_df(df_show: pd.DataFrame, title: str | None = None):
    if title:
        st.subheader(title)
    st.dataframe(df_show, use_container_width=True, hide_index=True)

# =====================================================
# CONFIG
# =====================================================
st.set_page_config(page_title="üìà B√°o c√°o Doanh thu", layout="wide")
st.title("üìà B√°o c√°o Doanh thu")

# =====================================================
# LOAD
# =====================================================
df = get_active_data()
st.sidebar.caption(
    "üîé ƒêang d√πng ngu·ªìn: **{}**".format(st.session_state.get("active_source", "default"))
)

df = ensure_datetime(df)
df = fix_numeric(df)

if df.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch. Ki·ªÉm tra l·∫°i ngu·ªìn d·ªØ li·ªáu.")
    st.stop()

# =====================================================
# SIDEBAR FILTER (Brand ‚Üí Region ‚Üí Store)
# =====================================================
def with_all_option(values: list[str], label_all="All"):
    return [label_all] + values
def normalize_filter(selected, all_values, label_all="All"):
    if (not selected) or (label_all in selected):
        return all_values
    return selected

with st.sidebar:
    st.header("üéõ B·ªô l·ªçc d·ªØ li·ªáu")

    time_grain = st.selectbox(
        "Ph√¢n t√≠ch theo",
        ["Ng√†y", "Tu·∫ßn", "Th√°ng", "Qu√Ω"],
        key="rev_time_grain",
    )

    start_date = st.date_input(
        "T·ª´ ng√†y",
        df["Ng√†y"].min().date(),
        key="rev_start_date",
    )
    end_date = st.date_input(
        "ƒê·∫øn ng√†y",
        df["Ng√†y"].max().date(),
        key="rev_end_date",
    )

    # Lo·∫°i CT ƒë·ªôc l·∫≠p
    all_loaict = sorted(df["LoaiCT"].dropna().unique()) if "LoaiCT" in df.columns else []
    loaict_ui = st.multiselect(
        "LoaiCT", with_all_option(all_loaict), default=["All"], key="rev_loaict"
    )
    loaict_filter = normalize_filter(loaict_ui, all_loaict)

    # Brand -> Region -> Store (cascading)
    all_brands = sorted(df["Brand"].dropna().unique()) if "Brand" in df.columns else []
    brand_ui = st.multiselect(
        "Brand", with_all_option(all_brands), default=["All"], key="rev_brand"
    )
    brand_filter = normalize_filter(brand_ui, all_brands)

    df_b = df[df["Brand"].isin(brand_filter)] if brand_filter else df.iloc[0:0]

    all_regions = sorted(df_b["Region"].dropna().unique()) if "Region" in df_b.columns else []
    region_ui = st.multiselect(
        "Region", with_all_option(all_regions), default=["All"], key="rev_region"
    )
    region_filter = normalize_filter(region_ui, all_regions)

    df_br = df_b[df_b["Region"].isin(region_filter)] if region_filter else df_b.iloc[0:0]

    all_stores = sorted(df_br["ƒêi·ªÉm_mua_h√†ng"].dropna().unique()) if "ƒêi·ªÉm_mua_h√†ng" in df_br.columns else []
    store_ui = st.multiselect(
        "ƒêi·ªÉm mua h√†ng", with_all_option(all_stores), default=["All"], key="rev_store"
    )
    store_filter = normalize_filter(store_ui, all_stores)

    # Check SƒêT & Ki·ªÉm tra t√™n
    all_checksdt = sorted(df["Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i"].dropna().unique()) if "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i" in df.columns else []
    checksdt_ui = st.multiselect(
        "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i",
        with_all_option(all_checksdt),
        default=["All"],
        key="rev_checksdt",
    )
    checksdt_filter = normalize_filter(checksdt_ui, all_checksdt)

    all_checkten = sorted(df["Ki·ªÉm_tra_t√™n"].dropna().unique()) if "Ki·ªÉm_tra_t√™n" in df.columns else []
    checkten_ui = st.multiselect(
        "Ki·ªÉm_tra_t√™n",
        with_all_option(all_checkten),
        default=["All"],
        key="rev_checkten",
    )
    checkten_filter = normalize_filter(checkten_ui, all_checkten)


# =====================================================
# APPLY FILTER
# =====================================================
mask = (
    (df["Ng√†y"] >= pd.to_datetime(start_date))
    & (df["Ng√†y"] <= pd.to_datetime(end_date))
)

if "LoaiCT" in df.columns:
    mask &= df["LoaiCT"].isin(loaict_filter if loaict_filter else [])
if "Brand" in df.columns:
    mask &= df["Brand"].isin(brand_filter if brand_filter else [])
if "Region" in df.columns:
    mask &= df["Region"].isin(region_filter if region_filter else [])
if "ƒêi·ªÉm_mua_h√†ng" in df.columns:
    mask &= df["ƒêi·ªÉm_mua_h√†ng"].isin(store_filter if store_filter else [])
if "Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i" in df.columns:
    mask &= df["Tr·∫°ng_th√°i_s·ªë_ƒëi·ªán_tho·∫°i"].isin(checksdt_filter if checksdt_filter else [])
if "Ki·ªÉm_tra_t√™n" in df.columns:
    mask &= df["Ki·ªÉm_tra_t√™n"].isin(checkten_filter if checkten_filter else [])

df_filtered = df.loc[mask].copy()

if df_filtered.empty:
    st.warning("‚ö† Kh√¥ng c√≥ d·ªØ li·ªáu sau khi √°p b·ªô l·ªçc.")
    st.stop()

# =====================================================
# HELPER: TIME KEY
# =====================================================
def add_time_key(df_in: pd.DataFrame, grain: str):
    df_out = df_in.copy()
    if grain == "Ng√†y":
        df_out["Key"] = df_out["Ng√†y"].dt.date  # datetime.date
        df_out["Year"] = df_out["Ng√†y"].dt.year
        group_cols = ["Key"]
    else:
        df_out["Year"] = df_out["Ng√†y"].dt.year
        if grain == "Tu·∫ßn":
            df_out["Key"] = df_out["Ng√†y"].dt.isocalendar().week.astype(int)
        elif grain == "Th√°ng":
            df_out["Key"] = df_out["Ng√†y"].dt.month.astype(int)
        elif grain == "Qu√Ω":
            df_out["Key"] = df_out["Ng√†y"].dt.quarter.astype(int)
        group_cols = ["Year", "Key"]
    return df_out, group_cols

# =====================================================
# SUMMARY TABLE
# =====================================================
def summarize_revenue(df_in: pd.DataFrame, grain: str) -> pd.DataFrame:
    if df_in.empty:
        return pd.DataFrame()

    df_tmp, group_cols = add_time_key(df_in, grain)

    summary = (
        df_tmp.groupby(group_cols)
        .agg(
            T·ªïng_Gross=("T·ªïng_Gross", "sum"),
            T·ªïng_Net=("T·ªïng_Net", "sum"),
            S·ªë_KH=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
            S·ªë_ƒë∆°n_h√†ng=("S·ªë_CT", "nunique"),
        )
        .reset_index()
    )

    summary["T·ª∑_l·ªá_CK (%)"] = (
        100 * (1 - summary["T·ªïng_Net"] / summary["T·ªïng_Gross"])
    ).where(summary["T·ªïng_Gross"] != 0, 0)

    summary = summary.sort_values(group_cols)

    for col in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng"]:
        prev_col = f"Prev_{col}"
        pct_col = f"%_So_s√°nh_{col}"
        summary[prev_col] = summary[col].shift(1)
        summary[pct_col] = (
            (summary[col] - summary[prev_col]) / summary[prev_col] * 100
        ).where(summary[prev_col].notna() & (summary[prev_col] != 0))

    return summary

# =====================================================
# TOP/BOTTOM STORE (l·ªçc theo k·ª≥ ƒë∆∞·ª£c ch·ªçn)
# =====================================================
def top_bottom_store(df_in: pd.DataFrame, grain: str, top: bool = True, year=None, key=None) -> pd.DataFrame:
    if df_in.empty:
        return pd.DataFrame()

    df_store, group_cols = add_time_key(df_in, grain)
    group_cols_store = ["ƒêi·ªÉm_mua_h√†ng"] + group_cols

    grouped = (
        df_store.groupby(group_cols_store, as_index=False)[["T·ªïng_Gross", "T·ªïng_Net"]]
        .sum()
    )

    grouped["T·ª∑_l·ªá_CK (%)"] = (
        100 * (1 - grouped["T·ªïng_Net"] / grouped["T·ªïng_Gross"])
    ).where(grouped["T·ªïng_Gross"] != 0, 0)

    grouped = grouped.sort_values(["ƒêi·ªÉm_mua_h√†ng"] + group_cols)
    grouped["Prev"] = grouped.groupby("ƒêi·ªÉm_mua_h√†ng")["T·ªïng_Net"].shift(1)
    grouped["Change%"] = (
        (grouped["T·ªïng_Net"] - grouped["Prev"]) / grouped["Prev"] * 100
    ).where(grouped["Prev"].notna() & (grouped["Prev"] != 0))

    if grain == "Ng√†y":
        sel_key = key if key is not None else grouped["Key"].max()
        mask = grouped["Key"] == sel_key
    else:
        if (year is None) or (key is None):
            sel_year = grouped["Year"].max()
            sel_key = grouped.query("Year == @sel_year")["Key"].max()
        else:
            sel_year = year
            sel_key = key
        mask = (grouped["Year"] == sel_year) & (grouped["Key"] == sel_key)

    out = grouped.loc[mask].copy()
    out = out.sort_values("T·ªïng_Net", ascending=not top).head(10)
    return out

# =====================================================
# VIEW: RAW FILTERED (tu·ª≥ ch·ªçn)
# =====================================================
with st.expander("üìë Xem d·ªØ li·ªáu ƒë√£ l·ªçc (m·ªü/ƒë√≥ng)", expanded=False):
    st.dataframe(df_filtered, use_container_width=True)

# =====================================================
# SUMMARY DISPLAY + CHART
# =====================================================
st.subheader("üìä T·ªïng h·ª£p doanh thu")
df_summary = summarize_revenue(df_filtered, time_grain)

if df_summary.empty:
    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu sau khi l·ªçc.")
    st.stop()

# T·∫°o c·ªôt label hi·ªÉn th·ªã ƒë·∫πp
df_summary_show = df_summary.copy()

if time_grain == "Ng√†y":
    # Key l√† date
    df_summary_show["K·ª≥"] = pd.to_datetime(df_summary_show["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
else:
    if time_grain == "Tu·∫ßn":
        df_summary_show["K·ª≥"] = df_summary_show.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        df_summary_show["K·ª≥"] = df_summary_show.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:  # Qu√Ω
        df_summary_show["K·ª≥"] = df_summary_show.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

# Format s·ªë b·∫±ng Python
for c in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng",
          "Prev_T·ªïng_Gross", "Prev_T·ªïng_Net", "Prev_S·ªë_KH", "Prev_S·ªë_ƒë∆°n_h√†ng"]:
    if c in df_summary_show.columns:
        df_summary_show[c] = df_summary_show[c].apply(fmt_int)

for c in ["T·ª∑_l·ªá_CK (%)", "%_So_s√°nh_T·ªïng_Gross", "%_So_s√°nh_T·ªïng_Net", "%_So_s√°nh_S·ªë_KH", "%_So_s√°nh_S·ªë_ƒë∆°n_h√†ng"]:
    if c in df_summary_show.columns:
        df_summary_show[c] = df_summary_show[c].apply(lambda v: fmt_pct(v, 2, with_sign=(c.startswith("%_So_s√°nh"))))

# Hi·ªÉn th·ªã b·∫£ng summary
show_cols = ["K·ª≥"]
for c in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng", "T·ª∑_l·ªá_CK (%)",
          "Prev_T·ªïng_Net", "%_So_s√°nh_T·ªïng_Net"]:
    if c in df_summary_show.columns:
        show_cols.append(c)

show_df(df_summary_show[show_cols], title=None)

# Chart (plotly) d√πng d·ªØ li·ªáu g·ªëc (ch∆∞a format)
fig = px.line(
    df_summary,
    x="Key",
    y=["T·ªïng_Gross", "T·ªïng_Net"],
    markers=True,
    title=f"Doanh thu theo {time_grain}",
)
st.plotly_chart(fig, use_container_width=True)

# =====================================================
# REGION REPORT + FILTER "CH·ªåN K·ª≤"
# =====================================================
st.subheader("üåç Doanh thu theo Region")

df_region, group_cols = add_time_key(df_filtered, time_grain)
group_cols_region = ["Region"] + group_cols

grouped_region = (
    df_region.groupby(group_cols_region, as_index=False)
    .agg(
        T·ªïng_Gross=("T·ªïng_Gross", "sum"),
        T·ªïng_Net=("T·ªïng_Net", "sum"),
        S·ªë_KH=("S·ªë_ƒëi·ªán_tho·∫°i", "nunique"),
        S·ªë_ƒë∆°n_h√†ng=("S·ªë_CT", "nunique"),
    )
)

grouped_region["T·ª∑_l·ªá_CK (%)"] = (
    100 * (1 - grouped_region["T·ªïng_Net"] / grouped_region["T·ªïng_Gross"])
).where(grouped_region["T·ªïng_Gross"] != 0, 0)

# So s√°nh k·ª≥ tr∆∞·ªõc theo t·ª´ng Region
grouped_region = grouped_region.sort_values(["Region"] + group_cols)
for col in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng"]:
    prev_col = f"Prev_{col}"
    pct_col = f"%_So_s√°nh_{col}"
    grouped_region[prev_col] = grouped_region.groupby("Region")[col].shift(1)
    grouped_region[pct_col] = (
        (grouped_region[col] - grouped_region[prev_col]) / grouped_region[prev_col] * 100
    ).where(grouped_region[prev_col].notna() & (grouped_region[prev_col] != 0))

# ====== Ch·ªçn k·ª≥ ƒë·ªÉ xem Region
st.markdown("### üîç Ch·ªçn k·ª≥ ƒë·ªÉ xem b·∫£ng Region")

if time_grain == "Ng√†y":
    periods = (
        df_summary[["Key"]]
        .drop_duplicates()
        .sort_values("Key")
        .copy()
    )
    periods["label"] = pd.to_datetime(periods["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
    sel_label = st.selectbox("K·ª≥ (Ng√†y)", periods["label"].tolist(), index=len(periods)-1, key="rev_region_period")
    sel_key = periods.loc[periods["label"] == sel_label, "Key"].iloc[0]
    region_mask = grouped_region["Key"] == sel_key
else:
    periods = (
        df_summary[["Year", "Key"]]
        .drop_duplicates()
        .sort_values(["Year", "Key"])
        .copy()
    )
    if time_grain == "Tu·∫ßn":
        periods["label"] = periods.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        periods["label"] = periods.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:  # Qu√Ω
        periods["label"] = periods.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

    sel_label = st.selectbox("K·ª≥", periods["label"].tolist(), index=len(periods)-1, key="rev_region_period")
    row = periods.loc[periods["label"] == sel_label].iloc[0]
    sel_year = int(row["Year"])
    sel_key = int(row["Key"])
    region_mask = (grouped_region["Year"] == sel_year) & (grouped_region["Key"] == sel_key)

df_region_view = grouped_region.loc[region_mask].copy()
df_region_view = df_region_view.sort_values("T·ªïng_Net", ascending=False)

# Format hi·ªÉn th·ªã Region
df_region_show = df_region_view.copy()
if time_grain == "Ng√†y":
    df_region_show["K·ª≥"] = pd.to_datetime(df_region_show["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
else:
    if time_grain == "Tu·∫ßn":
        df_region_show["K·ª≥"] = df_region_show.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        df_region_show["K·ª≥"] = df_region_show.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:
        df_region_show["K·ª≥"] = df_region_show.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

for c in ["T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng",
          "Prev_T·ªïng_Gross", "Prev_T·ªïng_Net", "Prev_S·ªë_KH", "Prev_S·ªë_ƒë∆°n_h√†ng"]:
    if c in df_region_show.columns:
        df_region_show[c] = df_region_show[c].apply(fmt_int)

for c in ["T·ª∑_l·ªá_CK (%)", "%_So_s√°nh_T·ªïng_Gross", "%_So_s√°nh_T·ªïng_Net", "%_So_s√°nh_S·ªë_KH", "%_So_s√°nh_S·ªë_ƒë∆°n_h√†ng"]:
    if c in df_region_show.columns:
        df_region_show[c] = df_region_show[c].apply(lambda v: fmt_pct(v, 2, with_sign=(c.startswith("%_So_s√°nh"))))

region_cols = ["K·ª≥", "Region", "T·ªïng_Gross", "T·ªïng_Net", "S·ªë_KH", "S·ªë_ƒë∆°n_h√†ng", "T·ª∑_l·ªá_CK (%)",
               "Prev_T·ªïng_Net", "%_So_s√°nh_T·ªïng_Net"]
region_cols = [c for c in region_cols if c in df_region_show.columns]
show_df(df_region_show[region_cols], title=None)

# =====================================================
# STORE TOP / BOTTOM + FILTER "CH·ªåN K·ª≤"
# =====================================================
st.subheader("üè™ Top/Bottom 10 ƒêi·ªÉm mua h√†ng")

st.markdown("### üîç Ch·ªçn k·ª≥ ƒë·ªÉ xem Top/Bottom")
if time_grain == "Ng√†y":
    period_df = df_summary[["Key"]].drop_duplicates().sort_values("Key").copy()
    period_df["label"] = pd.to_datetime(period_df["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
    sel_label2 = st.selectbox("K·ª≥ (Ng√†y)", period_df["label"].tolist(), index=len(period_df)-1, key="rev_store_period")
    sel_key2 = period_df.loc[period_df["label"] == sel_label2, "Key"].iloc[0]
    top10 = top_bottom_store(df_filtered, time_grain, top=True, key=sel_key2)
    bottom10 = top_bottom_store(df_filtered, time_grain, top=False, key=sel_key2)
else:
    period_df = df_summary[["Year", "Key"]].drop_duplicates().sort_values(["Year", "Key"]).copy()
    if time_grain == "Tu·∫ßn":
        period_df["label"] = period_df.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
    elif time_grain == "Th√°ng":
        period_df["label"] = period_df.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
    else:
        period_df["label"] = period_df.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

    sel_label2 = st.selectbox("K·ª≥", period_df["label"].tolist(), index=len(period_df)-1, key="rev_store_period")
    row2 = period_df.loc[period_df["label"] == sel_label2].iloc[0]
    sel_year2 = int(row2["Year"])
    sel_key2 = int(row2["Key"])
    top10 = top_bottom_store(df_filtered, time_grain, top=True, year=sel_year2, key=sel_key2)
    bottom10 = top_bottom_store(df_filtered, time_grain, top=False, year=sel_year2, key=sel_key2)

# Format Top/Bottom
def format_store_table(dfin: pd.DataFrame) -> pd.DataFrame:
    if dfin.empty:
        return dfin
    out = dfin.copy()

    # Key/Year hi·ªÉn th·ªã
    if time_grain == "Ng√†y":
        out["K·ª≥"] = pd.to_datetime(out["Key"], errors="coerce").dt.strftime("%Y-%m-%d")
    else:
        if time_grain == "Tu·∫ßn":
            out["K·ª≥"] = out.apply(lambda r: f"Tu·∫ßn {int(r['Key']):02d}/{int(r['Year'])}", axis=1)
        elif time_grain == "Th√°ng":
            out["K·ª≥"] = out.apply(lambda r: f"{int(r['Year'])}-{int(r['Key']):02d}", axis=1)
        else:
            out["K·ª≥"] = out.apply(lambda r: f"Q{int(r['Key'])} {int(r['Year'])}", axis=1)

    for c in ["T·ªïng_Gross", "T·ªïng_Net", "Prev"]:
        if c in out.columns:
            out[c] = out[c].apply(fmt_int)

    if "T·ª∑_l·ªá_CK (%)" in out.columns:
        out["T·ª∑_l·ªá_CK (%)"] = out["T·ª∑_l·ªá_CK (%)"].apply(lambda v: fmt_pct(v, 2))
    if "Change%" in out.columns:
        out["Change%"] = out["Change%"].apply(lambda v: fmt_pct(v, 2, with_sign=True))

    cols = ["K·ª≥", "ƒêi·ªÉm_mua_h√†ng", "T·ªïng_Gross", "T·ªïng_Net", "T·ª∑_l·ªá_CK (%)", "Prev", "Change%"]
    cols = [c for c in cols if c in out.columns]
    return out[cols]

top10_show = format_store_table(top10)
bottom10_show = format_store_table(bottom10)

col1, col2 = st.columns(2)
with col1:
    st.markdown("### üèÜ Top 10 ƒêi·ªÉm mua h√†ng")
    if top10_show.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
    else:
        st.dataframe(top10_show, use_container_width=True, hide_index=True)

with col2:
    st.markdown("### üìâ Bottom 10 ƒêi·ªÉm mua h√†ng")
    if bottom10_show.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
    else:
        st.dataframe(bottom10_show, use_container_width=True, hide_index=True)
